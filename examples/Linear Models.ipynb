{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dojo.linear import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    ")\n",
    "\n",
    "from dojo.split import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(100_000, 100)\n",
    "y = X @ np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Fitting...\n",
      "The model has been fitted successfully!\n",
      "-----------------------------------------\n",
      "CPU times: user 391 ms, sys: 98.3 ms, total: 490 ms\n",
      "Wall time: 278 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=4.92252193867726e-10,\n",
       "    coefs=[0.85869056 0.8485083  0.9814719  0.6315763  0.7692876  0.49395302\n",
       " 0.30218852 0.1409987  0.6968396  0.84074074 0.38648984 0.9993819\n",
       " 0.8471788  0.06541874 0.9535859  0.8547032  0.51387113 0.8051774\n",
       " 0.51079166 0.49442968 0.6219739  0.35366625 0.48971564 0.08108183\n",
       " 0.3986617  0.43956897 0.96607816 0.2504194  0.81903994 0.8438976\n",
       " 0.6791359  0.02024822 0.08011666 0.09331756 0.25270623 0.12343227\n",
       " 0.64374495 0.9778004  0.54654866 0.70960796 0.36296582 0.9938074\n",
       " 0.6271858  0.3185985  0.04955036 0.04813989 0.89952415 0.17039089\n",
       " 0.83487076 0.8036794  0.31749204 0.54393494 0.6440404  0.28684297\n",
       " 0.9377687  0.22510172 0.94756883 0.5394265  0.9172583  0.5249737\n",
       " 0.68010724 0.43570673 0.77951396 0.6484734  0.7931389  0.42580017\n",
       " 0.41925105 0.69447    0.7483189  0.6811544  0.23408535 0.3875497\n",
       " 0.08597634 0.48205975 0.23434867 0.19140144 0.27638686 0.3604168\n",
       " 0.42391527 0.9261185  0.5815237  0.6481983  0.9673202  0.6392126\n",
       " 0.22740252 0.63295835 0.04660981 0.18778633 0.30114082 0.10944786\n",
       " 0.6870229  0.26173759 0.5442978  0.08381202 0.6089716  0.46879178\n",
       " 0.20776212 0.4798896  0.11707333 0.4617677 ],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time linear_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.838087940938479e-13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_scores': array([3.04719416e-13, 3.07454136e-13, 3.06718461e-13, 3.06079364e-13,\n",
       "        3.05430277e-13, 3.05284142e-13, 3.05330648e-13, 3.06191789e-13,\n",
       "        3.04782750e-13, 3.06989005e-13]),\n",
       " 'test_scores': array([3.15296944e-13, 3.00484615e-13, 3.05442160e-13, 3.03056424e-13,\n",
       "        3.03923708e-13, 3.05239700e-13, 3.09794990e-13, 3.02045722e-13,\n",
       "        3.09752335e-13, 3.04671754e-13])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.verbose = False\n",
    "cross_validate(linear_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(alpha=7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "    alpha=7,\n",
       "    loss=<dojo.losses.CrossEntropy object at 0x10f320908>,\n",
       "    regularizer=<dojo.regularizers.L2 object at 0x10f320978>,\n",
       "    verbose=True,\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[1, 1],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 0]]\n",
    ")\n",
    "\n",
    "y = np.array([1 if x[0] and x[1] else 0 for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "10th iteration\n",
      "Loss: 0.2035867409220567\n",
      "--------------------------\n",
      "20th iteration\n",
      "Loss: 0.10892329504855713\n",
      "--------------------------\n",
      "30th iteration\n",
      "Loss: 0.08116938517885197\n",
      "--------------------------\n",
      "40th iteration\n",
      "Loss: 0.06594577732342094\n",
      "--------------------------\n",
      "50th iteration\n",
      "Loss: 0.05649696864786113\n",
      "--------------------------\n",
      "60th iteration\n",
      "Loss: 0.05015756105252146\n",
      "--------------------------\n",
      "70th iteration\n",
      "Loss: 0.04566891672203546\n",
      "--------------------------\n",
      "80th iteration\n",
      "Loss: 0.04236250536978306\n",
      "--------------------------\n",
      "90th iteration\n",
      "Loss: 0.03985217421107226\n",
      "--------------------------\n",
      "100th iteration\n",
      "Loss: 0.037900217982854124\n",
      "--------------------------\n",
      "110th iteration\n",
      "Loss: 0.036352878622072676\n",
      "--------------------------\n",
      "120th iteration\n",
      "Loss: 0.03510663639547598\n",
      "--------------------------\n",
      "130th iteration\n",
      "Loss: 0.03408944401180428\n",
      "--------------------------\n",
      "140th iteration\n",
      "Loss: 0.03324976963212996\n",
      "--------------------------\n",
      "150th iteration\n",
      "Loss: 0.03254987364663656\n",
      "--------------------------\n",
      "160th iteration\n",
      "Loss: 0.031961557813358035\n",
      "--------------------------\n",
      "170th iteration\n",
      "Loss: 0.03146338022212956\n",
      "--------------------------\n",
      "180th iteration\n",
      "Loss: 0.031038782214453938\n",
      "--------------------------\n",
      "190th iteration\n",
      "Loss: 0.030674814186049577\n",
      "--------------------------\n",
      "200th iteration\n",
      "Loss: 0.030361210492270186\n",
      "--------------------------\n",
      "210th iteration\n",
      "Loss: 0.03008975483827659\n",
      "--------------------------\n",
      "220th iteration\n",
      "Loss: 0.029853805842716387\n",
      "--------------------------\n",
      "230th iteration\n",
      "Loss: 0.029647946112400757\n",
      "--------------------------\n",
      "240th iteration\n",
      "Loss: 0.029467725433402404\n",
      "--------------------------\n",
      "250th iteration\n",
      "Loss: 0.029309459378255482\n",
      "--------------------------\n",
      "260th iteration\n",
      "Loss: 0.029170075352471517\n",
      "--------------------------\n",
      "270th iteration\n",
      "Loss: 0.02904700104683909\n",
      "--------------------------\n",
      "280th iteration\n",
      "Loss: 0.028938065126051835\n",
      "--------------------------\n",
      "290th iteration\n",
      "Loss: 0.028841433651511345\n",
      "--------------------------\n",
      "300th iteration\n",
      "Loss: 0.028755536015626745\n",
      "--------------------------\n",
      "310th iteration\n",
      "Loss: 0.028679037904415637\n",
      "--------------------------\n",
      "320th iteration\n",
      "Loss: 0.028610789354315342\n",
      "--------------------------\n",
      "330th iteration\n",
      "Loss: 0.028549803467149297\n",
      "--------------------------\n",
      "340th iteration\n",
      "Loss: 0.028495223187997555\n",
      "--------------------------\n",
      "350th iteration\n",
      "Loss: 0.02844630350208678\n",
      "--------------------------\n",
      "360th iteration\n",
      "Loss: 0.028402402021287583\n",
      "--------------------------\n",
      "370th iteration\n",
      "Loss: 0.028362954059370372\n",
      "--------------------------\n",
      "380th iteration\n",
      "Loss: 0.02832746694606183\n",
      "--------------------------\n",
      "390th iteration\n",
      "Loss: 0.028295507623768014\n",
      "--------------------------\n",
      "400th iteration\n",
      "Loss: 0.0282666942913605\n",
      "--------------------------\n",
      "410th iteration\n",
      "Loss: 0.028240695844412828\n",
      "--------------------------\n",
      "420th iteration\n",
      "Loss: 0.02821721334805504\n",
      "--------------------------\n",
      "430th iteration\n",
      "Loss: 0.028195984258928428\n",
      "--------------------------\n",
      "440th iteration\n",
      "Loss: 0.02817678064675932\n",
      "--------------------------\n",
      "450th iteration\n",
      "Loss: 0.028159392608472292\n",
      "--------------------------\n",
      "460th iteration\n",
      "Loss: 0.028143638639170805\n",
      "--------------------------\n",
      "470th iteration\n",
      "Loss: 0.02812935436962001\n",
      "--------------------------\n",
      "480th iteration\n",
      "Loss: 0.028116396946648886\n",
      "--------------------------\n",
      "490th iteration\n",
      "Loss: 0.028104633731805682\n",
      "--------------------------\n",
      "500th iteration\n",
      "Loss: 0.028093950765035805\n",
      "--------------------------\n",
      "510th iteration\n",
      "Loss: 0.02808423980888782\n",
      "--------------------------\n",
      "520th iteration\n",
      "Loss: 0.028075411718313313\n",
      "--------------------------\n",
      "530th iteration\n",
      "Loss: 0.028067379431304745\n",
      "--------------------------\n",
      "540th iteration\n",
      "Loss: 0.028060071432634393\n",
      "--------------------------\n",
      "550th iteration\n",
      "Loss: 0.02805341652142746\n",
      "--------------------------\n",
      "560th iteration\n",
      "Loss: 0.02804735347481823\n",
      "--------------------------\n",
      "570th iteration\n",
      "Loss: 0.02804182803767496\n",
      "--------------------------\n",
      "580th iteration\n",
      "Loss: 0.02803679174881163\n",
      "--------------------------\n",
      "590th iteration\n",
      "Loss: 0.02803219912639319\n",
      "--------------------------\n",
      "600th iteration\n",
      "Loss: 0.028028009774620066\n",
      "--------------------------\n",
      "610th iteration\n",
      "Loss: 0.028024185937328396\n",
      "--------------------------\n",
      "620th iteration\n",
      "Loss: 0.028020697180740163\n",
      "--------------------------\n",
      "630th iteration\n",
      "Loss: 0.028017508827696998\n",
      "--------------------------\n",
      "640th iteration\n",
      "Loss: 0.028014599664690894\n",
      "--------------------------\n",
      "650th iteration\n",
      "Loss: 0.028011940239872864\n",
      "--------------------------\n",
      "660th iteration\n",
      "Loss: 0.028009510097464323\n",
      "--------------------------\n",
      "670th iteration\n",
      "Loss: 0.02800728838157872\n",
      "--------------------------\n",
      "680th iteration\n",
      "Loss: 0.02800525901684155\n",
      "--------------------------\n",
      "690th iteration\n",
      "Loss: 0.02800340136282769\n",
      "--------------------------\n",
      "700th iteration\n",
      "Loss: 0.028001703383809994\n",
      "--------------------------\n",
      "710th iteration\n",
      "Loss: 0.02800014852205312\n",
      "--------------------------\n",
      "720th iteration\n",
      "Loss: 0.027998727841645085\n",
      "--------------------------\n",
      "730th iteration\n",
      "Loss: 0.027997426256329158\n",
      "--------------------------\n",
      "740th iteration\n",
      "Loss: 0.027996235772211546\n",
      "--------------------------\n",
      "750th iteration\n",
      "Loss: 0.027995145362942835\n",
      "--------------------------\n",
      "760th iteration\n",
      "Loss: 0.027994146321531355\n",
      "--------------------------\n",
      "770th iteration\n",
      "Loss: 0.027993233250835976\n",
      "--------------------------\n",
      "780th iteration\n",
      "Loss: 0.027992394933517878\n",
      "--------------------------\n",
      "790th iteration\n",
      "Loss: 0.027991628601048646\n",
      "--------------------------\n",
      "800th iteration\n",
      "Loss: 0.027990925891427182\n",
      "--------------------------\n",
      "810th iteration\n",
      "Loss: 0.027990282242666968\n",
      "--------------------------\n",
      "820th iteration\n",
      "Loss: 0.027989691770542124\n",
      "--------------------------\n",
      "830th iteration\n",
      "Loss: 0.027989150523572166\n",
      "--------------------------\n",
      "840th iteration\n",
      "Loss: 0.027988656270085878\n",
      "--------------------------\n",
      "850th iteration\n",
      "Loss: 0.02798820068743216\n",
      "--------------------------\n",
      "860th iteration\n",
      "Loss: 0.027987784068097418\n",
      "--------------------------\n",
      "870th iteration\n",
      "Loss: 0.027987402401757223\n",
      "--------------------------\n",
      "880th iteration\n",
      "Loss: 0.027987052263934595\n",
      "--------------------------\n",
      "890th iteration\n",
      "Loss: 0.02798673184213127\n",
      "--------------------------\n",
      "900th iteration\n",
      "Loss: 0.02798643699585613\n",
      "--------------------------\n",
      "910th iteration\n",
      "Loss: 0.02798616590134384\n",
      "--------------------------\n",
      "920th iteration\n",
      "Loss: 0.02798591817774554\n",
      "--------------------------\n",
      "930th iteration\n",
      "Loss: 0.027985691581790102\n",
      "--------------------------\n",
      "940th iteration\n",
      "Loss: 0.02798548368542523\n",
      "--------------------------\n",
      "950th iteration\n",
      "Loss: 0.02798529173142994\n",
      "--------------------------\n",
      "960th iteration\n",
      "Loss: 0.02798511539152472\n",
      "--------------------------\n",
      "970th iteration\n",
      "Loss: 0.0279849559092189\n",
      "--------------------------\n",
      "980th iteration\n",
      "Loss: 0.027984807403203887\n",
      "--------------------------\n",
      "990th iteration\n",
      "Loss: 0.027984672077706347\n",
      "--------------------------\n",
      "1000th iteration\n",
      "Loss: 0.027984547681046183\n",
      "--------------------------\n",
      "1010th iteration\n",
      "Loss: 0.027984432316086622\n",
      "--------------------------\n",
      "1020th iteration\n",
      "Loss: 0.027984327254092403\n",
      "--------------------------\n",
      "1030th iteration\n",
      "Loss: 0.027984231961234663\n",
      "--------------------------\n",
      "1040th iteration\n",
      "Loss: 0.02798414317303563\n",
      "--------------------------\n",
      "1050th iteration\n",
      "Loss: 0.02798406346988146\n",
      "--------------------------\n",
      "1060th iteration\n",
      "Loss: 0.027983987815748505\n",
      "--------------------------\n",
      "1070th iteration\n",
      "Loss: 0.02798391926207567\n",
      "--------------------------\n",
      "1080th iteration\n",
      "Loss: 0.02798385780802478\n",
      "--------------------------\n",
      "1090th iteration\n",
      "Loss: 0.027983798935823333\n",
      "--------------------------\n",
      "1100th iteration\n",
      "Loss: 0.02798374572120501\n",
      "--------------------------\n",
      "1110th iteration\n",
      "Loss: 0.027983698314065046\n",
      "--------------------------\n",
      "1120th iteration\n",
      "Loss: 0.027983652997949963\n",
      "--------------------------\n",
      "1130th iteration\n",
      "Loss: 0.02798361220983014\n",
      "--------------------------\n",
      "1140th iteration\n",
      "Loss: 0.027983574968535672\n",
      "--------------------------\n",
      "1150th iteration\n",
      "Loss: 0.027983540716421833\n",
      "--------------------------\n",
      "1160th iteration\n",
      "Loss: 0.027983508877925646\n",
      "--------------------------\n",
      "1170th iteration\n",
      "Loss: 0.027983478893793226\n",
      "--------------------------\n",
      "1180th iteration\n",
      "Loss: 0.027983453705098763\n",
      "--------------------------\n",
      "1190th iteration\n",
      "Loss: 0.02798342896357245\n",
      "--------------------------\n",
      "1200th iteration\n",
      "Loss: 0.027983406069225707\n",
      "--------------------------\n",
      "1210th iteration\n",
      "Loss: 0.027983386063191333\n",
      "--------------------------\n",
      "1220th iteration\n",
      "Loss: 0.02798336692170046\n",
      "--------------------------\n",
      "1230th iteration\n",
      "Loss: 0.02798334780965922\n",
      "--------------------------\n",
      "1240th iteration\n",
      "Loss: 0.027983332451927464\n",
      "CPU times: user 331 ms, sys: 44 ms, total: 375 ms\n",
      "Wall time: 336 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "    alpha=7,\n",
       "    loss=<dojo.losses.CrossEntropy object at 0x10f320908>,\n",
       "    regularizer=<dojo.regularizers.L2 object at 0x10f320978>,\n",
       "    verbose=True,\n",
       "    intercept=-13.46808533406562,\n",
       "    coefs=[[8.745498]\n",
       " [8.745498]],\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
