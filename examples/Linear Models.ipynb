{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dojo.linear import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    ")\n",
    "\n",
    "from dojo.split import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(100_000, 100)\n",
    "y = X @ np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Fitting...\n",
      "The model has been fitted successfully!\n",
      "-----------------------------------------\n",
      "CPU times: user 340 ms, sys: 80.6 ms, total: 421 ms\n",
      "Wall time: 287 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=-2.811660734965138e-10,\n",
       "    coefs=[0.6196718  0.43713844 0.74220306 0.72311854 0.19129854 0.52358466\n",
       " 0.339823   0.33761185 0.57139444 0.41121262 0.675932   0.972724\n",
       " 0.4306945  0.22053915 0.7820622  0.20297143 0.26428992 0.45461655\n",
       " 0.28317887 0.57301897 0.37528434 0.80873305 0.15731165 0.4964985\n",
       " 0.8908611  0.8580888  0.29665917 0.8793745  0.8460443  0.09827729\n",
       " 0.78595275 0.94024223 0.48335513 0.48141804 0.19465135 0.10252588\n",
       " 0.01879536 0.02147846 0.63665766 0.37849432 0.5329363  0.46626252\n",
       " 0.9153966  0.7817533  0.41741323 0.42179906 0.1033989  0.14664274\n",
       " 0.128285   0.99943864 0.26337704 0.85527074 0.37213886 0.5455693\n",
       " 0.9130645  0.16819906 0.587605   0.9505292  0.2678235  0.22585045\n",
       " 0.82175297 0.61211205 0.21254653 0.6034812  0.37494203 0.27584493\n",
       " 0.3868296  0.5386548  0.4010204  0.97363824 0.08451921 0.3682991\n",
       " 0.14321457 0.48753014 0.44610503 0.52408016 0.6103633  0.8000062\n",
       " 0.8962713  0.12899834 0.21752878 0.37358183 0.66241616 0.9051578\n",
       " 0.8433325  0.8916193  0.24546383 0.48343968 0.6683849  0.4408962\n",
       " 0.9910999  0.575085   0.12895963 0.18600282 0.9661909  0.16393949\n",
       " 0.86467874 0.7520379  0.90707177 0.3434937 ],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time linear_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.536339034553924e-13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_scores': array([2.75047016e-13, 2.75303567e-13, 2.76585136e-13, 2.75342412e-13,\n",
       "        2.76216881e-13, 2.74807246e-13, 2.74399744e-13, 2.75160620e-13,\n",
       "        2.74413763e-13, 2.74847245e-13]),\n",
       " 'test_scores': array([2.69684897e-13, 2.67523137e-13, 2.65694222e-13, 2.76878720e-13,\n",
       "        2.69008482e-13, 2.81695156e-13, 2.85362400e-13, 2.77958234e-13,\n",
       "        2.75809575e-13, 2.81334867e-13])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.verbose = False\n",
    "cross_validate(linear_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(alpha=7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "    alpha=7,\n",
       "    loss=<dojo.losses.CrossEntropy object at 0x11597d240>,\n",
       "    regularizer=<dojo.regularizers.L2 object at 0x11597d2b0>,\n",
       "    verbose=True,\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[1, 1],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 0]]\n",
    ")\n",
    "\n",
    "y = np.array([1 if x[0] and x[1] else 0 for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "10th iteration\n",
      "Loss: 0.20048215912217085\n",
      "--------------------------\n",
      "20th iteration\n",
      "Loss: 0.10420410449210024\n",
      "--------------------------\n",
      "30th iteration\n",
      "Loss: 0.0746452584116037\n",
      "--------------------------\n",
      "40th iteration\n",
      "Loss: 0.05795427930468573\n",
      "--------------------------\n",
      "50th iteration\n",
      "Loss: 0.04726761246134352\n",
      "--------------------------\n",
      "60th iteration\n",
      "Loss: 0.03985824674623936\n",
      "--------------------------\n",
      "70th iteration\n",
      "Loss: 0.03442859027342756\n",
      "--------------------------\n",
      "80th iteration\n",
      "Loss: 0.03028375884764044\n",
      "--------------------------\n",
      "90th iteration\n",
      "Loss: 0.027018806674275492\n",
      "--------------------------\n",
      "100th iteration\n",
      "Loss: 0.02438212667303834\n",
      "--------------------------\n",
      "110th iteration\n",
      "Loss: 0.022209342440585526\n",
      "--------------------------\n",
      "120th iteration\n",
      "Loss: 0.020388595882524296\n",
      "--------------------------\n",
      "130th iteration\n",
      "Loss: 0.018841191299778362\n",
      "--------------------------\n",
      "140th iteration\n",
      "Loss: 0.017510190291227946\n",
      "--------------------------\n",
      "150th iteration\n",
      "Loss: 0.016353377660696247\n",
      "--------------------------\n",
      "160th iteration\n",
      "Loss: 0.015338821093964486\n",
      "--------------------------\n",
      "170th iteration\n",
      "Loss: 0.014441911745201071\n",
      "--------------------------\n",
      "180th iteration\n",
      "Loss: 0.013643398444338272\n",
      "--------------------------\n",
      "190th iteration\n",
      "Loss: 0.012927995144897208\n",
      "--------------------------\n",
      "200th iteration\n",
      "Loss: 0.012283415531679222\n",
      "--------------------------\n",
      "210th iteration\n",
      "Loss: 0.011699680275251378\n",
      "--------------------------\n",
      "220th iteration\n",
      "Loss: 0.011168600252545006\n",
      "--------------------------\n",
      "230th iteration\n",
      "Loss: 0.01068337506832099\n",
      "--------------------------\n",
      "240th iteration\n",
      "Loss: 0.010238336079366922\n",
      "--------------------------\n",
      "250th iteration\n",
      "Loss: 0.009828704533177043\n",
      "--------------------------\n",
      "260th iteration\n",
      "Loss: 0.009450429051762023\n",
      "--------------------------\n",
      "270th iteration\n",
      "Loss: 0.009100056780134183\n",
      "--------------------------\n",
      "280th iteration\n",
      "Loss: 0.00877461246114638\n",
      "--------------------------\n",
      "290th iteration\n",
      "Loss: 0.008471536883746099\n",
      "--------------------------\n",
      "300th iteration\n",
      "Loss: 0.00818861033886159\n",
      "--------------------------\n",
      "310th iteration\n",
      "Loss: 0.0079238958973797\n",
      "--------------------------\n",
      "320th iteration\n",
      "Loss: 0.007675687435663439\n",
      "--------------------------\n",
      "330th iteration\n",
      "Loss: 0.0074424936673074035\n",
      "--------------------------\n",
      "340th iteration\n",
      "Loss: 0.007222998580881372\n",
      "--------------------------\n",
      "350th iteration\n",
      "Loss: 0.0070160282395747755\n",
      "--------------------------\n",
      "360th iteration\n",
      "Loss: 0.006820544546539962\n",
      "--------------------------\n",
      "370th iteration\n",
      "Loss: 0.00663562318689152\n",
      "--------------------------\n",
      "380th iteration\n",
      "Loss: 0.006460430280277475\n",
      "--------------------------\n",
      "390th iteration\n",
      "Loss: 0.006294217043348485\n",
      "--------------------------\n",
      "400th iteration\n",
      "Loss: 0.0061363118671670545\n",
      "--------------------------\n",
      "410th iteration\n",
      "Loss: 0.005986112305558483\n",
      "--------------------------\n",
      "420th iteration\n",
      "Loss: 0.0058430659214601275\n",
      "--------------------------\n",
      "430th iteration\n",
      "Loss: 0.005706674687312337\n",
      "--------------------------\n",
      "440th iteration\n",
      "Loss: 0.005576488662051266\n",
      "--------------------------\n",
      "450th iteration\n",
      "Loss: 0.005452090333587609\n",
      "--------------------------\n",
      "460th iteration\n",
      "Loss: 0.005333105944745067\n",
      "--------------------------\n",
      "470th iteration\n",
      "Loss: 0.005219187563112897\n",
      "--------------------------\n",
      "480th iteration\n",
      "Loss: 0.005110021030186523\n",
      "--------------------------\n",
      "490th iteration\n",
      "Loss: 0.0050053166409064565\n",
      "--------------------------\n",
      "500th iteration\n",
      "Loss: 0.004904803900471734\n",
      "--------------------------\n",
      "510th iteration\n",
      "Loss: 0.004808238147769725\n",
      "--------------------------\n",
      "520th iteration\n",
      "Loss: 0.004715394499558078\n",
      "--------------------------\n",
      "530th iteration\n",
      "Loss: 0.004626056239242767\n",
      "--------------------------\n",
      "540th iteration\n",
      "Loss: 0.004540031633647427\n",
      "--------------------------\n",
      "550th iteration\n",
      "Loss: 0.004457140963565608\n",
      "--------------------------\n",
      "560th iteration\n",
      "Loss: 0.0043772149601577735\n",
      "--------------------------\n",
      "570th iteration\n",
      "Loss: 0.0043000981951745575\n",
      "--------------------------\n",
      "580th iteration\n",
      "Loss: 0.004225645483544678\n",
      "--------------------------\n",
      "590th iteration\n",
      "Loss: 0.0041537214215923235\n",
      "--------------------------\n",
      "600th iteration\n",
      "Loss: 0.004084200645998216\n",
      "--------------------------\n",
      "610th iteration\n",
      "Loss: 0.004016961532785873\n",
      "--------------------------\n",
      "620th iteration\n",
      "Loss: 0.003951895313574713\n",
      "--------------------------\n",
      "630th iteration\n",
      "Loss: 0.00388889820722459\n",
      "--------------------------\n",
      "640th iteration\n",
      "Loss: 0.003827874134846687\n",
      "--------------------------\n",
      "650th iteration\n",
      "Loss: 0.0037687314819036086\n",
      "--------------------------\n",
      "660th iteration\n",
      "Loss: 0.0037113834704627117\n",
      "--------------------------\n",
      "670th iteration\n",
      "Loss: 0.003655754015590645\n",
      "--------------------------\n",
      "680th iteration\n",
      "Loss: 0.00360176431172299\n",
      "--------------------------\n",
      "690th iteration\n",
      "Loss: 0.003549341837427707\n",
      "--------------------------\n",
      "700th iteration\n",
      "Loss: 0.0034984205542043867\n",
      "--------------------------\n",
      "710th iteration\n",
      "Loss: 0.003448936452115414\n",
      "--------------------------\n",
      "720th iteration\n",
      "Loss: 0.003400830503988268\n",
      "--------------------------\n",
      "730th iteration\n",
      "Loss: 0.0033540472463232315\n",
      "--------------------------\n",
      "740th iteration\n",
      "Loss: 0.0033085293942263496\n",
      "--------------------------\n",
      "750th iteration\n",
      "Loss: 0.0032642289666604627\n",
      "--------------------------\n",
      "760th iteration\n",
      "Loss: 0.00322109733465776\n",
      "--------------------------\n",
      "770th iteration\n",
      "Loss: 0.003179087431960745\n",
      "--------------------------\n",
      "780th iteration\n",
      "Loss: 0.0031381582538053637\n",
      "--------------------------\n",
      "790th iteration\n",
      "Loss: 0.0030982665228435724\n",
      "--------------------------\n",
      "800th iteration\n",
      "Loss: 0.003059375422641458\n",
      "--------------------------\n",
      "810th iteration\n",
      "Loss: 0.0030214464406137596\n",
      "--------------------------\n",
      "820th iteration\n",
      "Loss: 0.0029844451765222847\n",
      "--------------------------\n",
      "830th iteration\n",
      "Loss: 0.002948337813826273\n",
      "--------------------------\n",
      "840th iteration\n",
      "Loss: 0.002913091757173108\n",
      "--------------------------\n",
      "850th iteration\n",
      "Loss: 0.0028786781574841437\n",
      "--------------------------\n",
      "860th iteration\n",
      "Loss: 0.0028450653396110146\n",
      "--------------------------\n",
      "870th iteration\n",
      "Loss: 0.0028122284276173313\n",
      "--------------------------\n",
      "880th iteration\n",
      "Loss: 0.0027801393224105996\n",
      "--------------------------\n",
      "890th iteration\n",
      "Loss: 0.0027487730526827053\n",
      "--------------------------\n",
      "900th iteration\n",
      "Loss: 0.0027181051790878415\n",
      "--------------------------\n",
      "910th iteration\n",
      "Loss: 0.00268811358315227\n",
      "--------------------------\n",
      "920th iteration\n",
      "Loss: 0.0026587750765899635\n",
      "--------------------------\n",
      "930th iteration\n",
      "Loss: 0.002630067826626285\n",
      "--------------------------\n",
      "940th iteration\n",
      "Loss: 0.0026019750812464326\n",
      "--------------------------\n",
      "950th iteration\n",
      "Loss: 0.0025744745308054007\n",
      "--------------------------\n",
      "960th iteration\n",
      "Loss: 0.002547548022595679\n",
      "--------------------------\n",
      "970th iteration\n",
      "Loss: 0.00252117909500607\n",
      "--------------------------\n",
      "980th iteration\n",
      "Loss: 0.0024953487066559053\n",
      "--------------------------\n",
      "990th iteration\n",
      "Loss: 0.0024700425672844408\n",
      "--------------------------\n",
      "1000th iteration\n",
      "Loss: 0.002445244059239263\n",
      "--------------------------\n",
      "1010th iteration\n",
      "Loss: 0.0024209370710408964\n",
      "--------------------------\n",
      "1020th iteration\n",
      "Loss: 0.002397107858132384\n",
      "--------------------------\n",
      "1030th iteration\n",
      "Loss: 0.0023737412104386903\n",
      "--------------------------\n",
      "1040th iteration\n",
      "Loss: 0.0023508257958951982\n",
      "--------------------------\n",
      "1050th iteration\n",
      "Loss: 0.002328348502567819\n",
      "--------------------------\n",
      "1060th iteration\n",
      "Loss: 0.0023062968522861637\n",
      "--------------------------\n",
      "1070th iteration\n",
      "Loss: 0.0022846576966373783\n",
      "--------------------------\n",
      "1080th iteration\n",
      "Loss: 0.0022634213088984835\n",
      "--------------------------\n",
      "1090th iteration\n",
      "Loss: 0.0022425746987599594\n",
      "--------------------------\n",
      "1100th iteration\n",
      "Loss: 0.0022221084860524396\n",
      "--------------------------\n",
      "1110th iteration\n",
      "Loss: 0.0022020120544536553\n",
      "--------------------------\n",
      "1120th iteration\n",
      "Loss: 0.0021822753213367966\n",
      "--------------------------\n",
      "1130th iteration\n",
      "Loss: 0.0021628892022294496\n",
      "--------------------------\n",
      "1140th iteration\n",
      "Loss: 0.002143844368578811\n",
      "--------------------------\n",
      "1150th iteration\n",
      "Loss: 0.002125130547570793\n",
      "--------------------------\n",
      "1160th iteration\n",
      "Loss: 0.0021067403417464954\n",
      "--------------------------\n",
      "1170th iteration\n",
      "Loss: 0.002088665364447135\n",
      "--------------------------\n",
      "1180th iteration\n",
      "Loss: 0.0020708979084603204\n",
      "--------------------------\n",
      "1190th iteration\n",
      "Loss: 0.0020534304595687847\n",
      "--------------------------\n",
      "1200th iteration\n",
      "Loss: 0.0020362543217134063\n",
      "--------------------------\n",
      "1210th iteration\n",
      "Loss: 0.002019362835922302\n",
      "--------------------------\n",
      "1220th iteration\n",
      "Loss: 0.002002748156801654\n",
      "--------------------------\n",
      "1230th iteration\n",
      "Loss: 0.001986404419004165\n",
      "--------------------------\n",
      "1240th iteration\n",
      "Loss: 0.0019703258925060957\n",
      "--------------------------\n",
      "1250th iteration\n",
      "Loss: 0.0019545047893876066\n",
      "--------------------------\n",
      "1260th iteration\n",
      "Loss: 0.0019389352574334358\n",
      "--------------------------\n",
      "1270th iteration\n",
      "Loss: 0.0019236120125700569\n",
      "--------------------------\n",
      "1280th iteration\n",
      "Loss: 0.0019085279654444853\n",
      "--------------------------\n",
      "1290th iteration\n",
      "Loss: 0.0018936791732964827\n",
      "--------------------------\n",
      "1300th iteration\n",
      "Loss: 0.001879059667053118\n",
      "--------------------------\n",
      "1310th iteration\n",
      "Loss: 0.0018646636191870698\n",
      "--------------------------\n",
      "1320th iteration\n",
      "Loss: 0.0018504863767352196\n",
      "--------------------------\n",
      "1330th iteration\n",
      "Loss: 0.0018365227715482942\n",
      "--------------------------\n",
      "1340th iteration\n",
      "Loss: 0.0018227681621393616\n",
      "--------------------------\n",
      "1350th iteration\n",
      "Loss: 0.0018092174015434366\n",
      "--------------------------\n",
      "1360th iteration\n",
      "Loss: 0.0017958662656893402\n",
      "--------------------------\n",
      "1370th iteration\n",
      "Loss: 0.0017827112205891906\n",
      "--------------------------\n",
      "1380th iteration\n",
      "Loss: 0.0017697468204664853\n",
      "--------------------------\n",
      "1390th iteration\n",
      "Loss: 0.001756969715172002\n",
      "--------------------------\n",
      "1400th iteration\n",
      "Loss: 0.001744375839281781\n",
      "--------------------------\n",
      "1410th iteration\n",
      "Loss: 0.001731961214762771\n",
      "--------------------------\n",
      "1420th iteration\n",
      "Loss: 0.0017197211777261947\n",
      "--------------------------\n",
      "1430th iteration\n",
      "Loss: 0.0017076536568988994\n",
      "--------------------------\n",
      "1440th iteration\n",
      "Loss: 0.0016957531921586626\n",
      "--------------------------\n",
      "1450th iteration\n",
      "Loss: 0.0016840163374937883\n",
      "--------------------------\n",
      "1460th iteration\n",
      "Loss: 0.0016724402801079762\n",
      "--------------------------\n",
      "1470th iteration\n",
      "Loss: 0.0016610222610318871\n",
      "--------------------------\n",
      "1480th iteration\n",
      "Loss: 0.0016497601286070249\n",
      "--------------------------\n",
      "1490th iteration\n",
      "Loss: 0.0016386506659088942\n",
      "--------------------------\n",
      "1500th iteration\n",
      "Loss: 0.0016276876201622833\n",
      "--------------------------\n",
      "1510th iteration\n",
      "Loss: 0.001616871589511762\n",
      "--------------------------\n",
      "1520th iteration\n",
      "Loss: 0.001606198096604083\n",
      "--------------------------\n",
      "1530th iteration\n",
      "Loss: 0.0015956641933759636\n",
      "--------------------------\n",
      "1540th iteration\n",
      "Loss: 0.0015852678789110017\n",
      "--------------------------\n",
      "1550th iteration\n",
      "Loss: 0.001575005774341495\n",
      "--------------------------\n",
      "1560th iteration\n",
      "Loss: 0.0015648750969764855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "1570th iteration\n",
      "Loss: 0.001554874687140096\n",
      "--------------------------\n",
      "1580th iteration\n",
      "Loss: 0.0015450008013279633\n",
      "--------------------------\n",
      "1590th iteration\n",
      "Loss: 0.0015352513237378953\n",
      "--------------------------\n",
      "1600th iteration\n",
      "Loss: 0.0015256240056479682\n",
      "--------------------------\n",
      "1610th iteration\n",
      "Loss: 0.0015161168099192505\n",
      "--------------------------\n",
      "1620th iteration\n",
      "Loss: 0.0015067270603106525\n",
      "--------------------------\n",
      "1630th iteration\n",
      "Loss: 0.0014974528042630845\n",
      "--------------------------\n",
      "1640th iteration\n",
      "Loss: 0.0014882919569319884\n",
      "--------------------------\n",
      "1650th iteration\n",
      "Loss: 0.0014792423056561007\n",
      "--------------------------\n",
      "1660th iteration\n",
      "Loss: 0.0014703020084832932\n",
      "--------------------------\n",
      "1670th iteration\n",
      "Loss: 0.0014614694194595719\n",
      "--------------------------\n",
      "1680th iteration\n",
      "Loss: 0.0014527416176711308\n",
      "--------------------------\n",
      "1690th iteration\n",
      "Loss: 0.001444117358861152\n",
      "--------------------------\n",
      "1700th iteration\n",
      "Loss: 0.0014355954171706875\n",
      "--------------------------\n",
      "1710th iteration\n",
      "Loss: 0.0014271726652275313\n",
      "--------------------------\n",
      "1720th iteration\n",
      "Loss: 0.0014188484237580427\n",
      "--------------------------\n",
      "1730th iteration\n",
      "Loss: 0.0014106205962543022\n",
      "--------------------------\n",
      "1740th iteration\n",
      "Loss: 0.0014024874391001779\n",
      "--------------------------\n",
      "1750th iteration\n",
      "Loss: 0.0013944478644231934\n",
      "--------------------------\n",
      "1760th iteration\n",
      "Loss: 0.001386499556660547\n",
      "--------------------------\n",
      "1770th iteration\n",
      "Loss: 0.0013786411709286722\n",
      "--------------------------\n",
      "1780th iteration\n",
      "Loss: 0.0013708719986447759\n",
      "--------------------------\n",
      "1790th iteration\n",
      "Loss: 0.0013631891994010628\n",
      "--------------------------\n",
      "1800th iteration\n",
      "Loss: 0.00135559241901635\n",
      "--------------------------\n",
      "1810th iteration\n",
      "Loss: 0.0013480793388886327\n",
      "--------------------------\n",
      "1820th iteration\n",
      "Loss: 0.0013406490361631657\n",
      "--------------------------\n",
      "1830th iteration\n",
      "Loss: 0.001333300002805225\n",
      "--------------------------\n",
      "1840th iteration\n",
      "Loss: 0.0013260312022979623\n",
      "--------------------------\n",
      "1850th iteration\n",
      "Loss: 0.0013188416133490348\n",
      "--------------------------\n",
      "1860th iteration\n",
      "Loss: 0.0013117290535344243\n",
      "--------------------------\n",
      "1870th iteration\n",
      "Loss: 0.0013046925503475983\n",
      "--------------------------\n",
      "1880th iteration\n",
      "Loss: 0.0012977311455315134\n",
      "--------------------------\n",
      "1890th iteration\n",
      "Loss: 0.0012908438946553906\n",
      "--------------------------\n",
      "1900th iteration\n",
      "Loss: 0.001284029003474963\n",
      "--------------------------\n",
      "1910th iteration\n",
      "Loss: 0.0012772855683021438\n",
      "--------------------------\n",
      "1920th iteration\n",
      "Loss: 0.0012706131257655576\n",
      "--------------------------\n",
      "1930th iteration\n",
      "Loss: 0.0012640099410698418\n",
      "--------------------------\n",
      "1940th iteration\n",
      "Loss: 0.0012574743096500937\n",
      "--------------------------\n",
      "1950th iteration\n",
      "Loss: 0.0012510060991805065\n",
      "--------------------------\n",
      "1960th iteration\n",
      "Loss: 0.0012446043375331482\n",
      "--------------------------\n",
      "1970th iteration\n",
      "Loss: 0.0012382673731082625\n",
      "--------------------------\n",
      "1980th iteration\n",
      "Loss: 0.0012319948256871804\n",
      "--------------------------\n",
      "1990th iteration\n",
      "Loss: 0.0012257856307038256\n",
      "--------------------------\n",
      "2000th iteration\n",
      "Loss: 0.001219638329882295\n",
      "--------------------------\n",
      "2010th iteration\n",
      "Loss: 0.0012135525777360267\n",
      "--------------------------\n",
      "2020th iteration\n",
      "Loss: 0.0012075270834641092\n",
      "--------------------------\n",
      "2030th iteration\n",
      "Loss: 0.0012015611161207745\n",
      "--------------------------\n",
      "2040th iteration\n",
      "Loss: 0.0011956536865890429\n",
      "--------------------------\n",
      "2050th iteration\n",
      "Loss: 0.0011898038209251706\n",
      "--------------------------\n",
      "2060th iteration\n",
      "Loss: 0.0011840109581787539\n",
      "--------------------------\n",
      "2070th iteration\n",
      "Loss: 0.0011782741479526852\n",
      "--------------------------\n",
      "2080th iteration\n",
      "Loss: 0.0011725928485610835\n",
      "--------------------------\n",
      "2090th iteration\n",
      "Loss: 0.0011669661323950044\n",
      "--------------------------\n",
      "2100th iteration\n",
      "Loss: 0.001161392825300656\n",
      "--------------------------\n",
      "2110th iteration\n",
      "Loss: 0.0011558728085416263\n",
      "--------------------------\n",
      "2120th iteration\n",
      "Loss: 0.0011504046722679293\n",
      "--------------------------\n",
      "2130th iteration\n",
      "Loss: 0.0011449881849521538\n",
      "--------------------------\n",
      "2140th iteration\n",
      "Loss: 0.001139622093834451\n",
      "--------------------------\n",
      "2150th iteration\n",
      "Loss: 0.001134306437897419\n",
      "--------------------------\n",
      "2160th iteration\n",
      "Loss: 0.001129039859755488\n",
      "--------------------------\n",
      "2170th iteration\n",
      "Loss: 0.0011238221578578392\n",
      "--------------------------\n",
      "2180th iteration\n",
      "Loss: 0.0011186523787317056\n",
      "--------------------------\n",
      "2190th iteration\n",
      "Loss: 0.0011135295833641832\n",
      "--------------------------\n",
      "2200th iteration\n",
      "Loss: 0.001108453840972857\n",
      "--------------------------\n",
      "2210th iteration\n",
      "Loss: 0.00110342410328164\n",
      "--------------------------\n",
      "2220th iteration\n",
      "Loss: 0.001098439461276539\n",
      "--------------------------\n",
      "2230th iteration\n",
      "Loss: 0.0010935000002019995\n",
      "--------------------------\n",
      "2240th iteration\n",
      "Loss: 0.0010886047026670577\n",
      "--------------------------\n",
      "2250th iteration\n",
      "Loss: 0.0010837528097697978\n",
      "--------------------------\n",
      "2260th iteration\n",
      "Loss: 0.0010789442992278535\n",
      "--------------------------\n",
      "2270th iteration\n",
      "Loss: 0.0010741781831827204\n",
      "--------------------------\n",
      "2280th iteration\n",
      "Loss: 0.001069453488656332\n",
      "--------------------------\n",
      "2290th iteration\n",
      "Loss: 0.0010647706897962653\n",
      "--------------------------\n",
      "2300th iteration\n",
      "Loss: 0.0010601282295417246\n",
      "--------------------------\n",
      "2310th iteration\n",
      "Loss: 0.001055526468946646\n",
      "--------------------------\n",
      "2320th iteration\n",
      "Loss: 0.0010509644644494706\n",
      "--------------------------\n",
      "2330th iteration\n",
      "Loss: 0.0010464411691964825\n",
      "--------------------------\n",
      "2340th iteration\n",
      "Loss: 0.0010419569538767323\n",
      "--------------------------\n",
      "2350th iteration\n",
      "Loss: 0.0010375111338618477\n",
      "--------------------------\n",
      "2360th iteration\n",
      "Loss: 0.0010331031498638941\n",
      "--------------------------\n",
      "2370th iteration\n",
      "Loss: 0.0010287317580018381\n",
      "--------------------------\n",
      "2380th iteration\n",
      "Loss: 0.0010243975709654078\n",
      "--------------------------\n",
      "2390th iteration\n",
      "Loss: 0.0010200997023915022\n",
      "--------------------------\n",
      "2400th iteration\n",
      "Loss: 0.0010158380760695298\n",
      "--------------------------\n",
      "2410th iteration\n",
      "Loss: 0.001011611594369236\n",
      "--------------------------\n",
      "2420th iteration\n",
      "Loss: 0.0010074199666668844\n",
      "--------------------------\n",
      "2430th iteration\n",
      "Loss: 0.0010032632427763204\n",
      "--------------------------\n",
      "2440th iteration\n",
      "Loss: 0.000999140461744215\n",
      "--------------------------\n",
      "2450th iteration\n",
      "Loss: 0.0009950513459811247\n",
      "--------------------------\n",
      "2460th iteration\n",
      "Loss: 0.000990995509586928\n",
      "--------------------------\n",
      "2470th iteration\n",
      "Loss: 0.0009869727926396113\n",
      "--------------------------\n",
      "2480th iteration\n",
      "Loss: 0.0009829824850619683\n",
      "--------------------------\n",
      "2490th iteration\n",
      "Loss: 0.000979024325709438\n",
      "--------------------------\n",
      "2500th iteration\n",
      "Loss: 0.000975097509415824\n",
      "--------------------------\n",
      "2510th iteration\n",
      "Loss: 0.0009712029846520066\n",
      "--------------------------\n",
      "2520th iteration\n",
      "Loss: 0.0009673389717676928\n",
      "--------------------------\n",
      "2530th iteration\n",
      "Loss: 0.0009635056623511035\n",
      "--------------------------\n",
      "2540th iteration\n",
      "Loss: 0.000959701952327808\n",
      "--------------------------\n",
      "2550th iteration\n",
      "Loss: 0.0009559285756598529\n",
      "--------------------------\n",
      "2560th iteration\n",
      "Loss: 0.0009521847587361591\n",
      "--------------------------\n",
      "2570th iteration\n",
      "Loss: 0.0009484705894109802\n",
      "--------------------------\n",
      "2580th iteration\n",
      "Loss: 0.0009447845638473429\n",
      "--------------------------\n",
      "2590th iteration\n",
      "Loss: 0.0009411274161840717\n",
      "--------------------------\n",
      "2600th iteration\n",
      "Loss: 0.0009374981860717112\n",
      "--------------------------\n",
      "2610th iteration\n",
      "Loss: 0.0009338969737786374\n",
      "--------------------------\n",
      "2620th iteration\n",
      "Loss: 0.0009303234595838627\n",
      "--------------------------\n",
      "2630th iteration\n",
      "Loss: 0.0009267770156455831\n",
      "--------------------------\n",
      "2640th iteration\n",
      "Loss: 0.000923257436566783\n",
      "--------------------------\n",
      "2650th iteration\n",
      "Loss: 0.000919764725162148\n",
      "--------------------------\n",
      "2660th iteration\n",
      "Loss: 0.0009162981638650362\n",
      "--------------------------\n",
      "2670th iteration\n",
      "Loss: 0.0009128578635893234\n",
      "--------------------------\n",
      "2680th iteration\n",
      "Loss: 0.0009094431167195737\n",
      "--------------------------\n",
      "2690th iteration\n",
      "Loss: 0.0009060534282986193\n",
      "--------------------------\n",
      "2700th iteration\n",
      "Loss: 0.0009026892205677872\n",
      "--------------------------\n",
      "2710th iteration\n",
      "Loss: 0.0008993499001173556\n",
      "--------------------------\n",
      "2720th iteration\n",
      "Loss: 0.0008960351826109238\n",
      "--------------------------\n",
      "2730th iteration\n",
      "Loss: 0.0008927447869326671\n",
      "--------------------------\n",
      "2740th iteration\n",
      "Loss: 0.000889478634525349\n",
      "--------------------------\n",
      "2750th iteration\n",
      "Loss: 0.0008862359514444825\n",
      "--------------------------\n",
      "2760th iteration\n",
      "Loss: 0.0008830171621331558\n",
      "--------------------------\n",
      "2770th iteration\n",
      "Loss: 0.0008798213028442663\n",
      "--------------------------\n",
      "2780th iteration\n",
      "Loss: 0.0008766484057839917\n",
      "--------------------------\n",
      "2790th iteration\n",
      "Loss: 0.0008734988935531653\n",
      "--------------------------\n",
      "2800th iteration\n",
      "Loss: 0.0008703713275525379\n",
      "--------------------------\n",
      "2810th iteration\n",
      "Loss: 0.0008672663309918762\n",
      "--------------------------\n",
      "2820th iteration\n",
      "Loss: 0.0008641833545936982\n",
      "--------------------------\n",
      "2830th iteration\n",
      "Loss: 0.0008611222421865182\n",
      "--------------------------\n",
      "2840th iteration\n",
      "Loss: 0.0008580826466249254\n",
      "--------------------------\n",
      "2850th iteration\n",
      "Loss: 0.0008550645124211065\n",
      "--------------------------\n",
      "2860th iteration\n",
      "Loss: 0.0008520674019253855\n",
      "--------------------------\n",
      "2870th iteration\n",
      "Loss: 0.0008490914540598784\n",
      "--------------------------\n",
      "2880th iteration\n",
      "Loss: 0.0008461358562649602\n",
      "--------------------------\n",
      "2890th iteration\n",
      "Loss: 0.0008432010356704966\n",
      "--------------------------\n",
      "2900th iteration\n",
      "Loss: 0.0008402866589498779\n",
      "--------------------------\n",
      "2910th iteration\n",
      "Loss: 0.0008373921149556003\n",
      "--------------------------\n",
      "2920th iteration\n",
      "Loss: 0.0008345176423648358\n",
      "--------------------------\n",
      "2930th iteration\n",
      "Loss: 0.0008316625433775319\n",
      "--------------------------\n",
      "2940th iteration\n",
      "Loss: 0.0008288266866250491\n",
      "--------------------------\n",
      "2950th iteration\n",
      "Loss: 0.0008260103123504638\n",
      "--------------------------\n",
      "2960th iteration\n",
      "Loss: 0.0008232131952929782\n",
      "--------------------------\n",
      "2970th iteration\n",
      "Loss: 0.0008204349286092298\n",
      "--------------------------\n",
      "2980th iteration\n",
      "Loss: 0.0008176751102828799\n",
      "--------------------------\n",
      "2990th iteration\n",
      "Loss: 0.0008149339826882298\n",
      "--------------------------\n",
      "3000th iteration\n",
      "Loss: 0.0008122112379404808\n",
      "--------------------------\n",
      "3010th iteration\n",
      "Loss: 0.0008095064807976997\n",
      "--------------------------\n",
      "3020th iteration\n",
      "Loss: 0.0008068195016566106\n",
      "--------------------------\n",
      "3030th iteration\n",
      "Loss: 0.0008041503636007838\n",
      "--------------------------\n",
      "3040th iteration\n",
      "Loss: 0.0008014990384013955\n",
      "--------------------------\n",
      "3050th iteration\n",
      "Loss: 0.0007988649601574933\n",
      "--------------------------\n",
      "3060th iteration\n",
      "Loss: 0.0007962483734153551\n",
      "--------------------------\n",
      "3070th iteration\n",
      "Loss: 0.0007936485399966425\n",
      "--------------------------\n",
      "3080th iteration\n",
      "Loss: 0.0007910658839571297\n",
      "--------------------------\n",
      "3090th iteration\n",
      "Loss: 0.0007884997623194986\n",
      "--------------------------\n",
      "3100th iteration\n",
      "Loss: 0.0007859500686726699\n",
      "--------------------------\n",
      "3110th iteration\n",
      "Loss: 0.000783417400245815\n",
      "--------------------------\n",
      "3120th iteration\n",
      "Loss: 0.0007809005071836995\n",
      "--------------------------\n",
      "3130th iteration\n",
      "Loss: 0.0007783999881455344\n",
      "--------------------------\n",
      "3140th iteration\n",
      "Loss: 0.0007759150415297437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "3150th iteration\n",
      "Loss: 0.0007734462631415785\n",
      "--------------------------\n",
      "3160th iteration\n",
      "Loss: 0.0007709929438957949\n",
      "--------------------------\n",
      "3170th iteration\n",
      "Loss: 0.000768555331241786\n",
      "--------------------------\n",
      "3180th iteration\n",
      "Loss: 0.0007661328958179068\n",
      "--------------------------\n",
      "3190th iteration\n",
      "Loss: 0.0007637257995917497\n",
      "--------------------------\n",
      "3200th iteration\n",
      "Loss: 0.0007613335190610543\n",
      "--------------------------\n",
      "3210th iteration\n",
      "Loss: 0.0007589565581179884\n",
      "--------------------------\n",
      "3220th iteration\n",
      "Loss: 0.0007565942261300906\n",
      "--------------------------\n",
      "3230th iteration\n",
      "Loss: 0.00075424668640079\n",
      "--------------------------\n",
      "3240th iteration\n",
      "Loss: 0.0007519133409472109\n",
      "--------------------------\n",
      "3250th iteration\n",
      "Loss: 0.0007495946074157563\n",
      "--------------------------\n",
      "3260th iteration\n",
      "Loss: 0.0007472901437294207\n",
      "--------------------------\n",
      "3270th iteration\n",
      "Loss: 0.0007449996115962621\n",
      "--------------------------\n",
      "3280th iteration\n",
      "Loss: 0.0007427231761786773\n",
      "--------------------------\n",
      "3290th iteration\n",
      "Loss: 0.0007404605850580634\n",
      "--------------------------\n",
      "3300th iteration\n",
      "Loss: 0.0007382117540703932\n",
      "--------------------------\n",
      "3310th iteration\n",
      "Loss: 0.0007359765171700536\n",
      "--------------------------\n",
      "3320th iteration\n",
      "Loss: 0.0007337546276373434\n",
      "--------------------------\n",
      "3330th iteration\n",
      "Loss: 0.000731546251532863\n",
      "--------------------------\n",
      "3340th iteration\n",
      "Loss: 0.0007293512254200461\n",
      "--------------------------\n",
      "3350th iteration\n",
      "Loss: 0.0007271691428003926\n",
      "--------------------------\n",
      "3360th iteration\n",
      "Loss: 0.0007250003334012467\n",
      "--------------------------\n",
      "3370th iteration\n",
      "Loss: 0.0007228442310282532\n",
      "--------------------------\n",
      "3380th iteration\n",
      "Loss: 0.0007207008415764213\n",
      "--------------------------\n",
      "3390th iteration\n",
      "Loss: 0.0007185700899636271\n",
      "--------------------------\n",
      "3400th iteration\n",
      "Loss: 0.0007164520623540045\n",
      "--------------------------\n",
      "3410th iteration\n",
      "Loss: 0.0007143464430315479\n",
      "--------------------------\n",
      "3420th iteration\n",
      "Loss: 0.000712253239135259\n",
      "--------------------------\n",
      "3430th iteration\n",
      "Loss: 0.0007101722184836846\n",
      "--------------------------\n",
      "3440th iteration\n",
      "Loss: 0.000708103230717621\n",
      "--------------------------\n",
      "3450th iteration\n",
      "Loss: 0.0007060462060780757\n",
      "--------------------------\n",
      "3460th iteration\n",
      "Loss: 0.0007040013121502213\n",
      "--------------------------\n",
      "3470th iteration\n",
      "Loss: 0.00070196824197272\n",
      "--------------------------\n",
      "3480th iteration\n",
      "Loss: 0.000699946613312168\n",
      "--------------------------\n",
      "3490th iteration\n",
      "Loss: 0.000697936439402589\n",
      "--------------------------\n",
      "3500th iteration\n",
      "Loss: 0.0006959381232367305\n",
      "--------------------------\n",
      "3510th iteration\n",
      "Loss: 0.0006939512068920539\n",
      "--------------------------\n",
      "3520th iteration\n",
      "Loss: 0.0006919756253829446\n",
      "--------------------------\n",
      "3530th iteration\n",
      "Loss: 0.0006900110820514321\n",
      "--------------------------\n",
      "3540th iteration\n",
      "Loss: 0.0006880577462818558\n",
      "--------------------------\n",
      "3550th iteration\n",
      "Loss: 0.0006861154005605909\n",
      "--------------------------\n",
      "3560th iteration\n",
      "Loss: 0.0006841839063060312\n",
      "--------------------------\n",
      "3570th iteration\n",
      "Loss: 0.0006822634322594002\n",
      "--------------------------\n",
      "3580th iteration\n",
      "Loss: 0.0006803535346419902\n",
      "--------------------------\n",
      "3590th iteration\n",
      "Loss: 0.0006784543069738134\n",
      "--------------------------\n",
      "3600th iteration\n",
      "Loss: 0.0006765659173487156\n",
      "--------------------------\n",
      "3610th iteration\n",
      "Loss: 0.0006746877751214064\n",
      "--------------------------\n",
      "3620th iteration\n",
      "Loss: 0.0006728201259446719\n",
      "--------------------------\n",
      "3630th iteration\n",
      "Loss: 0.0006709627610343526\n",
      "--------------------------\n",
      "3640th iteration\n",
      "Loss: 0.0006691154736679465\n",
      "--------------------------\n",
      "3650th iteration\n",
      "Loss: 0.0006672785081692974\n",
      "--------------------------\n",
      "3660th iteration\n",
      "Loss: 0.0006654515089185762\n",
      "--------------------------\n",
      "3670th iteration\n",
      "Loss: 0.000663634496095793\n",
      "--------------------------\n",
      "3680th iteration\n",
      "Loss: 0.0006618274151754271\n",
      "--------------------------\n",
      "3690th iteration\n",
      "Loss: 0.0006600302120566962\n",
      "--------------------------\n",
      "3700th iteration\n",
      "Loss: 0.0006582425376950467\n",
      "--------------------------\n",
      "3710th iteration\n",
      "Loss: 0.0006564645619434624\n",
      "--------------------------\n",
      "3720th iteration\n",
      "Loss: 0.0006546963792051683\n",
      "--------------------------\n",
      "3730th iteration\n",
      "Loss: 0.0006529374236281279\n",
      "--------------------------\n",
      "3740th iteration\n",
      "Loss: 0.0006511879385467066\n",
      "--------------------------\n",
      "3750th iteration\n",
      "Loss: 0.000649447945969493\n",
      "--------------------------\n",
      "3760th iteration\n",
      "Loss: 0.0006477171769301011\n",
      "--------------------------\n",
      "3770th iteration\n",
      "Loss: 0.0006459954375582973\n",
      "--------------------------\n",
      "3780th iteration\n",
      "Loss: 0.0006442829693854231\n",
      "--------------------------\n",
      "3790th iteration\n",
      "Loss: 0.0006425794346697727\n",
      "--------------------------\n",
      "3800th iteration\n",
      "Loss: 0.000640884930296696\n",
      "--------------------------\n",
      "3810th iteration\n",
      "Loss: 0.000639199623619772\n",
      "--------------------------\n",
      "3820th iteration\n",
      "Loss: 0.0006375228935998536\n",
      "--------------------------\n",
      "3830th iteration\n",
      "Loss: 0.0006358548386089214\n",
      "--------------------------\n",
      "3840th iteration\n",
      "Loss: 0.0006341955557845723\n",
      "--------------------------\n",
      "3850th iteration\n",
      "Loss: 0.0006325449992488208\n",
      "--------------------------\n",
      "3860th iteration\n",
      "Loss: 0.0006309029111102802\n",
      "--------------------------\n",
      "3870th iteration\n",
      "Loss: 0.0006292695300081071\n",
      "--------------------------\n",
      "3880th iteration\n",
      "Loss: 0.0006276444584319237\n",
      "--------------------------\n",
      "3890th iteration\n",
      "Loss: 0.0006260277240323391\n",
      "--------------------------\n",
      "3900th iteration\n",
      "Loss: 0.0006244193540390376\n",
      "--------------------------\n",
      "3910th iteration\n",
      "Loss: 0.0006228190259678051\n",
      "--------------------------\n",
      "3920th iteration\n",
      "Loss: 0.0006212270475073664\n",
      "--------------------------\n",
      "3930th iteration\n",
      "Loss: 0.0006196431671177427\n",
      "--------------------------\n",
      "3940th iteration\n",
      "Loss: 0.0006180674129040953\n",
      "--------------------------\n",
      "3950th iteration\n",
      "Loss: 0.0006164994668566933\n",
      "--------------------------\n",
      "3960th iteration\n",
      "Loss: 0.0006149397036544367\n",
      "--------------------------\n",
      "3970th iteration\n",
      "Loss: 0.0006133873933955134\n",
      "--------------------------\n",
      "3980th iteration\n",
      "Loss: 0.0006118433229744117\n",
      "--------------------------\n",
      "3990th iteration\n",
      "Loss: 0.0006103069707585084\n",
      "--------------------------\n",
      "4000th iteration\n",
      "Loss: 0.0006087779567461039\n",
      "--------------------------\n",
      "4010th iteration\n",
      "Loss: 0.0006072570623565567\n",
      "--------------------------\n",
      "4020th iteration\n",
      "Loss: 0.0006057434306503085\n",
      "--------------------------\n",
      "4030th iteration\n",
      "Loss: 0.0006042373650797362\n",
      "--------------------------\n",
      "4040th iteration\n",
      "Loss: 0.0006027388279624955\n",
      "--------------------------\n",
      "4050th iteration\n",
      "Loss: 0.0006012475795657558\n",
      "--------------------------\n",
      "4060th iteration\n",
      "Loss: 0.0005997637859587917\n",
      "--------------------------\n",
      "4070th iteration\n",
      "Loss: 0.0005982872759501722\n",
      "--------------------------\n",
      "4080th iteration\n",
      "Loss: 0.0005968180807177538\n",
      "--------------------------\n",
      "4090th iteration\n",
      "Loss: 0.0005953560974333636\n",
      "--------------------------\n",
      "4100th iteration\n",
      "Loss: 0.000593901090951271\n",
      "--------------------------\n",
      "4110th iteration\n",
      "Loss: 0.0005924530276171702\n",
      "--------------------------\n",
      "4120th iteration\n",
      "Loss: 0.0005910123379607171\n",
      "--------------------------\n",
      "4130th iteration\n",
      "Loss: 0.0005895785224944087\n",
      "--------------------------\n",
      "4140th iteration\n",
      "Loss: 0.0005881517460615861\n",
      "--------------------------\n",
      "4150th iteration\n",
      "Loss: 0.000586731579577402\n",
      "--------------------------\n",
      "4160th iteration\n",
      "Loss: 0.0005853186482735256\n",
      "--------------------------\n",
      "4170th iteration\n",
      "Loss: 0.0005839123269982075\n",
      "--------------------------\n",
      "4180th iteration\n",
      "Loss: 0.0005825127151144213\n",
      "--------------------------\n",
      "4190th iteration\n",
      "Loss: 0.0005811197805673972\n",
      "--------------------------\n",
      "4200th iteration\n",
      "Loss: 0.0005797333614535892\n",
      "--------------------------\n",
      "4210th iteration\n",
      "Loss: 0.0005783538162188293\n",
      "--------------------------\n",
      "4220th iteration\n",
      "Loss: 0.0005769807232579479\n",
      "--------------------------\n",
      "4230th iteration\n",
      "Loss: 0.0005756139876480446\n",
      "--------------------------\n",
      "4240th iteration\n",
      "Loss: 0.0005742538372526335\n",
      "--------------------------\n",
      "4250th iteration\n",
      "Loss: 0.0005728999836878042\n",
      "--------------------------\n",
      "4260th iteration\n",
      "Loss: 0.0005715525898653248\n",
      "--------------------------\n",
      "4270th iteration\n",
      "Loss: 0.00057021162521487\n",
      "--------------------------\n",
      "4280th iteration\n",
      "Loss: 0.0005688769317414459\n",
      "--------------------------\n",
      "4290th iteration\n",
      "Loss: 0.0005675484164863345\n",
      "--------------------------\n",
      "4300th iteration\n",
      "Loss: 0.0005662259237398882\n",
      "--------------------------\n",
      "4310th iteration\n",
      "Loss: 0.0005649098059837447\n",
      "--------------------------\n",
      "4320th iteration\n",
      "Loss: 0.0005635994642112925\n",
      "--------------------------\n",
      "4330th iteration\n",
      "Loss: 0.0005622953769184751\n",
      "--------------------------\n",
      "4340th iteration\n",
      "Loss: 0.0005609975147487042\n",
      "--------------------------\n",
      "4350th iteration\n",
      "Loss: 0.0005597055346553673\n",
      "--------------------------\n",
      "4360th iteration\n",
      "Loss: 0.0005584194097924635\n",
      "--------------------------\n",
      "4370th iteration\n",
      "Loss: 0.0005571393009151735\n",
      "--------------------------\n",
      "4380th iteration\n",
      "Loss: 0.0005558649931733597\n",
      "--------------------------\n",
      "4390th iteration\n",
      "Loss: 0.0005545963357739006\n",
      "--------------------------\n",
      "4400th iteration\n",
      "Loss: 0.0005533334274516257\n",
      "--------------------------\n",
      "4410th iteration\n",
      "Loss: 0.0005520764278615077\n",
      "--------------------------\n",
      "4420th iteration\n",
      "Loss: 0.000550824939140826\n",
      "--------------------------\n",
      "4430th iteration\n",
      "Loss: 0.0005495793065708202\n",
      "--------------------------\n",
      "4440th iteration\n",
      "Loss: 0.0005483393187562333\n",
      "--------------------------\n",
      "4450th iteration\n",
      "Loss: 0.0005471047661192805\n",
      "--------------------------\n",
      "4460th iteration\n",
      "Loss: 0.0005458758694176811\n",
      "--------------------------\n",
      "4470th iteration\n",
      "Loss: 0.0005446525419449931\n",
      "--------------------------\n",
      "4480th iteration\n",
      "Loss: 0.0005434344538819249\n",
      "--------------------------\n",
      "4490th iteration\n",
      "Loss: 0.0005422220688307665\n",
      "--------------------------\n",
      "4500th iteration\n",
      "Loss: 0.0005410148753572024\n",
      "--------------------------\n",
      "4510th iteration\n",
      "Loss: 0.0005398130324485721\n",
      "--------------------------\n",
      "4520th iteration\n",
      "Loss: 0.0005386166372055907\n",
      "--------------------------\n",
      "4530th iteration\n",
      "Loss: 0.0005374253638612824\n",
      "--------------------------\n",
      "4540th iteration\n",
      "Loss: 0.0005362393705774387\n",
      "--------------------------\n",
      "4550th iteration\n",
      "Loss: 0.0005350587540466508\n",
      "--------------------------\n",
      "4560th iteration\n",
      "Loss: 0.0005338833705145968\n",
      "--------------------------\n",
      "4570th iteration\n",
      "Loss: 0.0005327130176750838\n",
      "--------------------------\n",
      "4580th iteration\n",
      "Loss: 0.0005315478526039009\n",
      "--------------------------\n",
      "4590th iteration\n",
      "Loss: 0.0005303876740256925\n",
      "--------------------------\n",
      "4600th iteration\n",
      "Loss: 0.0005292324604106455\n",
      "--------------------------\n",
      "4610th iteration\n",
      "Loss: 0.0005280823680214124\n",
      "--------------------------\n",
      "4620th iteration\n",
      "Loss: 0.0005269373744015406\n",
      "--------------------------\n",
      "4630th iteration\n",
      "Loss: 0.0005257972803108063\n",
      "--------------------------\n",
      "4640th iteration\n",
      "Loss: 0.000524661946992411\n",
      "--------------------------\n",
      "4650th iteration\n",
      "Loss: 0.0005235316478431336\n",
      "--------------------------\n",
      "4660th iteration\n",
      "Loss: 0.0005224061851167063\n",
      "--------------------------\n",
      "4670th iteration\n",
      "Loss: 0.0005212855380870868\n",
      "--------------------------\n",
      "4680th iteration\n",
      "Loss: 0.0005201695694544526\n",
      "--------------------------\n",
      "4690th iteration\n",
      "Loss: 0.0005190585505405675\n",
      "--------------------------\n",
      "4700th iteration\n",
      "Loss: 0.0005179521693723934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "4710th iteration\n",
      "Loss: 0.000516850522346411\n",
      "--------------------------\n",
      "4720th iteration\n",
      "Loss: 0.0005157534735889975\n",
      "--------------------------\n",
      "4730th iteration\n",
      "Loss: 0.0005146611192116828\n",
      "--------------------------\n",
      "4740th iteration\n",
      "Loss: 0.0005135733240422579\n",
      "--------------------------\n",
      "4750th iteration\n",
      "Loss: 0.0005124903563460265\n",
      "--------------------------\n",
      "4760th iteration\n",
      "Loss: 0.0005114117364091073\n",
      "--------------------------\n",
      "4770th iteration\n",
      "Loss: 0.0005103377325807992\n",
      "--------------------------\n",
      "4780th iteration\n",
      "Loss: 0.0005092682110713203\n",
      "--------------------------\n",
      "4790th iteration\n",
      "Loss: 0.0005082031531493117\n",
      "--------------------------\n",
      "4800th iteration\n",
      "Loss: 0.0005071425401819813\n",
      "--------------------------\n",
      "4810th iteration\n",
      "Loss: 0.0005060863536333505\n",
      "--------------------------\n",
      "4820th iteration\n",
      "Loss: 0.0005050344051367295\n",
      "--------------------------\n",
      "4830th iteration\n",
      "Loss: 0.0005039870165565829\n",
      "--------------------------\n",
      "4840th iteration\n",
      "Loss: 0.0005029438301390096\n",
      "--------------------------\n",
      "4850th iteration\n",
      "Loss: 0.0005019049976551569\n",
      "--------------------------\n",
      "4860th iteration\n",
      "Loss: 0.000500870332513698\n",
      "--------------------------\n",
      "4870th iteration\n",
      "Loss: 0.0004998401541506014\n",
      "--------------------------\n",
      "4880th iteration\n",
      "Loss: 0.0004988142198698842\n",
      "--------------------------\n",
      "4890th iteration\n",
      "Loss: 0.0004977922889046358\n",
      "--------------------------\n",
      "4900th iteration\n",
      "Loss: 0.0004967746238629055\n",
      "--------------------------\n",
      "4910th iteration\n",
      "Loss: 0.0004957612071382145\n",
      "--------------------------\n",
      "4920th iteration\n",
      "Loss: 0.0004947517437623901\n",
      "--------------------------\n",
      "4930th iteration\n",
      "Loss: 0.0004937464948923881\n",
      "--------------------------\n",
      "4940th iteration\n",
      "Loss: 0.000492745166859802\n",
      "--------------------------\n",
      "4950th iteration\n",
      "Loss: 0.0004917480198614986\n",
      "--------------------------\n",
      "4960th iteration\n",
      "Loss: 0.0004907548716052107\n",
      "--------------------------\n",
      "4970th iteration\n",
      "Loss: 0.0004897658708034583\n",
      "--------------------------\n",
      "4980th iteration\n",
      "Loss: 0.0004887807263567497\n",
      "--------------------------\n",
      "4990th iteration\n",
      "Loss: 0.00048779958714076246\n",
      "--------------------------\n",
      "5000th iteration\n",
      "Loss: 0.00048682210938411205\n",
      "--------------------------\n",
      "5010th iteration\n",
      "Loss: 0.0004858487149039183\n",
      "--------------------------\n",
      "5020th iteration\n",
      "Loss: 0.00048487938703679174\n",
      "--------------------------\n",
      "5030th iteration\n",
      "Loss: 0.00048391378355650656\n",
      "--------------------------\n",
      "5040th iteration\n",
      "Loss: 0.0004829521065772706\n",
      "--------------------------\n",
      "5050th iteration\n",
      "Loss: 0.0004819940700267032\n",
      "--------------------------\n",
      "5060th iteration\n",
      "Loss: 0.0004810397677304974\n",
      "--------------------------\n",
      "5070th iteration\n",
      "Loss: 0.0004800893465701109\n",
      "--------------------------\n",
      "5080th iteration\n",
      "Loss: 0.0004791426835294021\n",
      "--------------------------\n",
      "5090th iteration\n",
      "Loss: 0.0004781998710432478\n",
      "--------------------------\n",
      "5100th iteration\n",
      "Loss: 0.0004772607331374769\n",
      "--------------------------\n",
      "5110th iteration\n",
      "Loss: 0.0004763249883237073\n",
      "--------------------------\n",
      "5120th iteration\n",
      "Loss: 0.0004753930504324395\n",
      "--------------------------\n",
      "5130th iteration\n",
      "Loss: 0.00047446485108467687\n",
      "--------------------------\n",
      "5140th iteration\n",
      "Loss: 0.00047354026927208856\n",
      "--------------------------\n",
      "5150th iteration\n",
      "Loss: 0.00047261929090726136\n",
      "--------------------------\n",
      "5160th iteration\n",
      "Loss: 0.00047170179615640186\n",
      "--------------------------\n",
      "5170th iteration\n",
      "Loss: 0.000470787718884364\n",
      "--------------------------\n",
      "5180th iteration\n",
      "Loss: 0.00046987746773623413\n",
      "--------------------------\n",
      "5190th iteration\n",
      "Loss: 0.00046897076436544955\n",
      "--------------------------\n",
      "5200th iteration\n",
      "Loss: 0.00046806733252993145\n",
      "--------------------------\n",
      "5210th iteration\n",
      "Loss: 0.0004671673172524644\n",
      "--------------------------\n",
      "5220th iteration\n",
      "Loss: 0.00046627081011336774\n",
      "--------------------------\n",
      "5230th iteration\n",
      "Loss: 0.000465377901952168\n",
      "--------------------------\n",
      "5240th iteration\n",
      "Loss: 0.0004644883702848992\n",
      "--------------------------\n",
      "5250th iteration\n",
      "Loss: 0.0004636020462925718\n",
      "--------------------------\n",
      "5260th iteration\n",
      "Loss: 0.0004627190737959692\n",
      "--------------------------\n",
      "5270th iteration\n",
      "Loss: 0.00046183975089218634\n",
      "--------------------------\n",
      "5280th iteration\n",
      "Loss: 0.0004609635978414359\n",
      "--------------------------\n",
      "5290th iteration\n",
      "Loss: 0.0004600907577521048\n",
      "--------------------------\n",
      "5300th iteration\n",
      "Loss: 0.00045922111508160413\n",
      "--------------------------\n",
      "5310th iteration\n",
      "Loss: 0.00045835491500313035\n",
      "--------------------------\n",
      "5320th iteration\n",
      "Loss: 0.00045749199028906844\n",
      "--------------------------\n",
      "5330th iteration\n",
      "Loss: 0.0004566323285890546\n",
      "--------------------------\n",
      "5340th iteration\n",
      "Loss: 0.00045577566201028725\n",
      "--------------------------\n",
      "5350th iteration\n",
      "Loss: 0.00045492254103389636\n",
      "--------------------------\n",
      "5360th iteration\n",
      "Loss: 0.0004540723915329585\n",
      "--------------------------\n",
      "5370th iteration\n",
      "Loss: 0.00045322530448631775\n",
      "--------------------------\n",
      "5380th iteration\n",
      "Loss: 0.0004523814208981595\n",
      "--------------------------\n",
      "5390th iteration\n",
      "Loss: 0.0004515409313447593\n",
      "--------------------------\n",
      "5400th iteration\n",
      "Loss: 0.0004507033677736744\n",
      "--------------------------\n",
      "5410th iteration\n",
      "Loss: 0.00044986871969466055\n",
      "--------------------------\n",
      "5420th iteration\n",
      "Loss: 0.00044903742995163116\n",
      "--------------------------\n",
      "5430th iteration\n",
      "Loss: 0.00044820923427734295\n",
      "--------------------------\n",
      "5440th iteration\n",
      "Loss: 0.0004473839706682352\n",
      "--------------------------\n",
      "5450th iteration\n",
      "Loss: 0.0004465616786474229\n",
      "--------------------------\n",
      "5460th iteration\n",
      "Loss: 0.0004457425473960298\n",
      "--------------------------\n",
      "5470th iteration\n",
      "Loss: 0.00044492626563636534\n",
      "--------------------------\n",
      "5480th iteration\n",
      "Loss: 0.00044411297265214533\n",
      "--------------------------\n",
      "5490th iteration\n",
      "Loss: 0.00044330280668759066\n",
      "--------------------------\n",
      "5500th iteration\n",
      "Loss: 0.0004424955575238836\n",
      "--------------------------\n",
      "5510th iteration\n",
      "Loss: 0.00044169116506129484\n",
      "--------------------------\n",
      "5520th iteration\n",
      "Loss: 0.00044088961907007686\n",
      "--------------------------\n",
      "5530th iteration\n",
      "Loss: 0.0004400912055292416\n",
      "--------------------------\n",
      "5540th iteration\n",
      "Loss: 0.00043929546922888895\n",
      "--------------------------\n",
      "5550th iteration\n",
      "Loss: 0.0004385025976126909\n",
      "--------------------------\n",
      "5560th iteration\n",
      "Loss: 0.00043771277674474436\n",
      "--------------------------\n",
      "5570th iteration\n",
      "Loss: 0.0004369257502510362\n",
      "--------------------------\n",
      "5580th iteration\n",
      "Loss: 0.0004361413125018013\n",
      "--------------------------\n",
      "5590th iteration\n",
      "Loss: 0.0004353598941185851\n",
      "--------------------------\n",
      "5600th iteration\n",
      "Loss: 0.0004345813376787471\n",
      "--------------------------\n",
      "5610th iteration\n",
      "Loss: 0.00043380538954918056\n",
      "--------------------------\n",
      "5620th iteration\n",
      "Loss: 0.00043303238073039813\n",
      "--------------------------\n",
      "5630th iteration\n",
      "Loss: 0.0004322621064976901\n",
      "--------------------------\n",
      "5640th iteration\n",
      "Loss: 0.00043149426677282766\n",
      "--------------------------\n",
      "5650th iteration\n",
      "Loss: 0.00043072952982377776\n",
      "--------------------------\n",
      "5660th iteration\n",
      "Loss: 0.0004299672088068742\n",
      "--------------------------\n",
      "5670th iteration\n",
      "Loss: 0.0004292076808214092\n",
      "--------------------------\n",
      "5680th iteration\n",
      "Loss: 0.0004284509358406757\n",
      "--------------------------\n",
      "5690th iteration\n",
      "Loss: 0.0004276967240038591\n",
      "--------------------------\n",
      "5700th iteration\n",
      "Loss: 0.0004269451324065356\n",
      "--------------------------\n",
      "5710th iteration\n",
      "Loss: 0.00042619634312068215\n",
      "--------------------------\n",
      "5720th iteration\n",
      "Loss: 0.00042545005970396574\n",
      "--------------------------\n",
      "5730th iteration\n",
      "Loss: 0.0004247064641434579\n",
      "--------------------------\n",
      "5740th iteration\n",
      "Loss: 0.00042396540425288366\n",
      "--------------------------\n",
      "5750th iteration\n",
      "Loss: 0.00042322682381539493\n",
      "--------------------------\n",
      "5760th iteration\n",
      "Loss: 0.00042249099871426485\n",
      "--------------------------\n",
      "5770th iteration\n",
      "Loss: 0.0004217577298207862\n",
      "--------------------------\n",
      "5780th iteration\n",
      "Loss: 0.000421026677693013\n",
      "--------------------------\n",
      "5790th iteration\n",
      "Loss: 0.00042029868378949415\n",
      "--------------------------\n",
      "5800th iteration\n",
      "Loss: 0.00041957274833455036\n",
      "--------------------------\n",
      "5810th iteration\n",
      "Loss: 0.0004188494757459792\n",
      "--------------------------\n",
      "5820th iteration\n",
      "Loss: 0.00041812876278749813\n",
      "--------------------------\n",
      "5830th iteration\n",
      "Loss: 0.00041741036642723014\n",
      "--------------------------\n",
      "5840th iteration\n",
      "Loss: 0.000416694652903847\n",
      "--------------------------\n",
      "5850th iteration\n",
      "Loss: 0.000415981286036548\n",
      "--------------------------\n",
      "5860th iteration\n",
      "Loss: 0.0004152702113868913\n",
      "--------------------------\n",
      "5870th iteration\n",
      "Loss: 0.00041456174688410635\n",
      "--------------------------\n",
      "5880th iteration\n",
      "Loss: 0.0004138555583594952\n",
      "--------------------------\n",
      "5890th iteration\n",
      "Loss: 0.0004131519163535894\n",
      "--------------------------\n",
      "5900th iteration\n",
      "Loss: 0.00041245067318116714\n",
      "--------------------------\n",
      "5910th iteration\n",
      "Loss: 0.0004117514512048718\n",
      "--------------------------\n",
      "5920th iteration\n",
      "Loss: 0.00041105516631145843\n",
      "--------------------------\n",
      "5930th iteration\n",
      "Loss: 0.0004103607489496149\n",
      "--------------------------\n",
      "5940th iteration\n",
      "Loss: 0.0004096688369444397\n",
      "--------------------------\n",
      "5950th iteration\n",
      "Loss: 0.00040897942157770684\n",
      "--------------------------\n",
      "5960th iteration\n",
      "Loss: 0.00040829199040533335\n",
      "--------------------------\n",
      "5970th iteration\n",
      "Loss: 0.00040760717740780377\n",
      "--------------------------\n",
      "5980th iteration\n",
      "Loss: 0.00040692447119503034\n",
      "--------------------------\n",
      "5990th iteration\n",
      "Loss: 0.00040624422957074007\n",
      "--------------------------\n",
      "6000th iteration\n",
      "Loss: 0.0004055660800751811\n",
      "--------------------------\n",
      "6010th iteration\n",
      "Loss: 0.00040489010684421146\n",
      "--------------------------\n",
      "6020th iteration\n",
      "Loss: 0.00040421675617538137\n",
      "--------------------------\n",
      "6030th iteration\n",
      "Loss: 0.0004035452492264271\n",
      "--------------------------\n",
      "6040th iteration\n",
      "Loss: 0.0004028762131903492\n",
      "--------------------------\n",
      "6050th iteration\n",
      "Loss: 0.00040220918832223535\n",
      "--------------------------\n",
      "6060th iteration\n",
      "Loss: 0.00040154448358352456\n",
      "--------------------------\n",
      "6070th iteration\n",
      "Loss: 0.0004008820461605959\n",
      "--------------------------\n",
      "6080th iteration\n",
      "Loss: 0.00040022164398651855\n",
      "--------------------------\n",
      "6090th iteration\n",
      "Loss: 0.0003995635395257695\n",
      "--------------------------\n",
      "6100th iteration\n",
      "Loss: 0.0003989074565387365\n",
      "--------------------------\n",
      "6110th iteration\n",
      "Loss: 0.00039825370132942845\n",
      "--------------------------\n",
      "6120th iteration\n",
      "Loss: 0.0003976020429817372\n",
      "--------------------------\n",
      "6130th iteration\n",
      "Loss: 0.00039695238566990417\n",
      "--------------------------\n",
      "6140th iteration\n",
      "Loss: 0.00039630498977536593\n",
      "--------------------------\n",
      "6150th iteration\n",
      "Loss: 0.0003956595370346744\n",
      "--------------------------\n",
      "6160th iteration\n",
      "Loss: 0.0003950163758625304\n",
      "--------------------------\n",
      "6170th iteration\n",
      "Loss: 0.0003943751003632766\n",
      "--------------------------\n",
      "6180th iteration\n",
      "Loss: 0.00039373614640611645\n",
      "--------------------------\n",
      "6190th iteration\n",
      "Loss: 0.000393099065135393\n",
      "--------------------------\n",
      "6200th iteration\n",
      "Loss: 0.0003924641149539355\n",
      "--------------------------\n",
      "6210th iteration\n",
      "Loss: 0.000391831200950259\n",
      "--------------------------\n",
      "6220th iteration\n",
      "Loss: 0.0003912003604671424\n",
      "--------------------------\n",
      "6230th iteration\n",
      "Loss: 0.00039057149915438106\n",
      "--------------------------\n",
      "6240th iteration\n",
      "Loss: 0.00038994461073193413\n",
      "--------------------------\n",
      "6250th iteration\n",
      "Loss: 0.000389319863623764\n",
      "--------------------------\n",
      "6260th iteration\n",
      "Loss: 0.00038869690196035466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "6270th iteration\n",
      "Loss: 0.00038807615567778794\n",
      "--------------------------\n",
      "6280th iteration\n",
      "Loss: 0.0003874570958121685\n",
      "--------------------------\n",
      "6290th iteration\n",
      "Loss: 0.00038684041172517793\n",
      "--------------------------\n",
      "6300th iteration\n",
      "Loss: 0.0003862254453629351\n",
      "--------------------------\n",
      "6310th iteration\n",
      "Loss: 0.0003856126242086945\n",
      "--------------------------\n",
      "6320th iteration\n",
      "Loss: 0.00038500146610346767\n",
      "--------------------------\n",
      "6330th iteration\n",
      "Loss: 0.0003843924836305207\n",
      "--------------------------\n",
      "6340th iteration\n",
      "Loss: 0.0003837852390344258\n",
      "--------------------------\n",
      "6350th iteration\n",
      "Loss: 0.00038318007097458407\n",
      "--------------------------\n",
      "6360th iteration\n",
      "Loss: 0.0003825767151683177\n",
      "--------------------------\n",
      "6370th iteration\n",
      "Loss: 0.00038197520891344297\n",
      "--------------------------\n",
      "6380th iteration\n",
      "Loss: 0.00038137563201543336\n",
      "--------------------------\n",
      "6390th iteration\n",
      "Loss: 0.00038077789294865865\n",
      "--------------------------\n",
      "6400th iteration\n",
      "Loss: 0.00038018215658735166\n",
      "--------------------------\n",
      "6410th iteration\n",
      "Loss: 0.0003795881610039794\n",
      "--------------------------\n",
      "6420th iteration\n",
      "Loss: 0.0003789960284810403\n",
      "--------------------------\n",
      "6430th iteration\n",
      "Loss: 0.0003784057531944766\n",
      "--------------------------\n",
      "6440th iteration\n",
      "Loss: 0.00037781728696927085\n",
      "--------------------------\n",
      "6450th iteration\n",
      "Loss: 0.0003772307088395628\n",
      "--------------------------\n",
      "6460th iteration\n",
      "Loss: 0.0003766459283679154\n",
      "--------------------------\n",
      "6470th iteration\n",
      "Loss: 0.00037606289782688075\n",
      "--------------------------\n",
      "6480th iteration\n",
      "Loss: 0.0003754817803687697\n",
      "--------------------------\n",
      "6490th iteration\n",
      "Loss: 0.0003749024017008634\n",
      "--------------------------\n",
      "6500th iteration\n",
      "Loss: 0.00037432479853775143\n",
      "--------------------------\n",
      "6510th iteration\n",
      "Loss: 0.00037374892349876897\n",
      "--------------------------\n",
      "6520th iteration\n",
      "Loss: 0.0003731749387824235\n",
      "--------------------------\n",
      "6530th iteration\n",
      "Loss: 0.00037260254583903194\n",
      "--------------------------\n",
      "6540th iteration\n",
      "Loss: 0.00037203203216050354\n",
      "--------------------------\n",
      "6550th iteration\n",
      "Loss: 0.0003714632251326603\n",
      "--------------------------\n",
      "6560th iteration\n",
      "Loss: 0.0003708962860131786\n",
      "--------------------------\n",
      "6570th iteration\n",
      "Loss: 0.00037033091812565313\n",
      "--------------------------\n",
      "6580th iteration\n",
      "Loss: 0.00036976732430289054\n",
      "--------------------------\n",
      "6590th iteration\n",
      "Loss: 0.00036920537483036233\n",
      "--------------------------\n",
      "6600th iteration\n",
      "Loss: 0.00036864510616349197\n",
      "--------------------------\n",
      "6610th iteration\n",
      "Loss: 0.00036808667839676454\n",
      "--------------------------\n",
      "6620th iteration\n",
      "Loss: 0.0003675297971603971\n",
      "--------------------------\n",
      "6630th iteration\n",
      "Loss: 0.0003669747461373848\n",
      "--------------------------\n",
      "6640th iteration\n",
      "Loss: 0.00036642127296714674\n",
      "--------------------------\n",
      "6650th iteration\n",
      "Loss: 0.00036586957824434607\n",
      "--------------------------\n",
      "6660th iteration\n",
      "Loss: 0.0003653193695951428\n",
      "--------------------------\n",
      "6670th iteration\n",
      "Loss: 0.0003647710110691964\n",
      "--------------------------\n",
      "6680th iteration\n",
      "Loss: 0.00036422404740284273\n",
      "--------------------------\n",
      "6690th iteration\n",
      "Loss: 0.0003636790051210098\n",
      "--------------------------\n",
      "6700th iteration\n",
      "Loss: 0.00036313526704420305\n",
      "--------------------------\n",
      "6710th iteration\n",
      "Loss: 0.00036259343985684884\n",
      "--------------------------\n",
      "6720th iteration\n",
      "Loss: 0.0003620529894670908\n",
      "--------------------------\n",
      "6730th iteration\n",
      "Loss: 0.00036151435820282955\n",
      "--------------------------\n",
      "6740th iteration\n",
      "Loss: 0.0003609771759106393\n",
      "--------------------------\n",
      "6750th iteration\n",
      "Loss: 0.00036044176196537765\n",
      "--------------------------\n",
      "6760th iteration\n",
      "Loss: 0.00035990770715959496\n",
      "--------------------------\n",
      "6770th iteration\n",
      "Loss: 0.0003593754512195734\n",
      "--------------------------\n",
      "6780th iteration\n",
      "Loss: 0.00035884462624834434\n",
      "--------------------------\n",
      "6790th iteration\n",
      "Loss: 0.00035831530860519815\n",
      "--------------------------\n",
      "6800th iteration\n",
      "Loss: 0.000357787815003327\n",
      "--------------------------\n",
      "6810th iteration\n",
      "Loss: 0.0003572615385682733\n",
      "--------------------------\n",
      "6820th iteration\n",
      "Loss: 0.00035673711646626684\n",
      "--------------------------\n",
      "6830th iteration\n",
      "Loss: 0.00035621394344001104\n",
      "--------------------------\n",
      "6840th iteration\n",
      "Loss: 0.0003556926147372283\n",
      "--------------------------\n",
      "6850th iteration\n",
      "Loss: 0.000355172606574251\n",
      "--------------------------\n",
      "6860th iteration\n",
      "Loss: 0.00035465415409419496\n",
      "--------------------------\n",
      "6870th iteration\n",
      "Loss: 0.0003541372924108772\n",
      "--------------------------\n",
      "6880th iteration\n",
      "Loss: 0.00035362173912540246\n",
      "--------------------------\n",
      "6890th iteration\n",
      "Loss: 0.00035310788679501705\n",
      "--------------------------\n",
      "6900th iteration\n",
      "Loss: 0.0003525952951227902\n",
      "--------------------------\n",
      "6910th iteration\n",
      "Loss: 0.0003520845531951544\n",
      "--------------------------\n",
      "6920th iteration\n",
      "Loss: 0.0003515749058279079\n",
      "--------------------------\n",
      "6930th iteration\n",
      "Loss: 0.00035106705925044975\n",
      "--------------------------\n",
      "6940th iteration\n",
      "Loss: 0.0003505603786170089\n",
      "--------------------------\n",
      "6950th iteration\n",
      "Loss: 0.00035005537145773067\n",
      "--------------------------\n",
      "6960th iteration\n",
      "Loss: 0.00034955175818002286\n",
      "--------------------------\n",
      "6970th iteration\n",
      "Loss: 0.00034904945655292994\n",
      "--------------------------\n",
      "6980th iteration\n",
      "Loss: 0.0003485487757866407\n",
      "--------------------------\n",
      "6990th iteration\n",
      "Loss: 0.0003480492815097486\n",
      "--------------------------\n",
      "7000th iteration\n",
      "Loss: 0.00034755163344518474\n",
      "--------------------------\n",
      "7010th iteration\n",
      "Loss: 0.000347055047114937\n",
      "--------------------------\n",
      "7020th iteration\n",
      "Loss: 0.00034656006424798084\n",
      "--------------------------\n",
      "7030th iteration\n",
      "Loss: 0.0003460664859018128\n",
      "--------------------------\n",
      "7040th iteration\n",
      "Loss: 0.00034557419180033833\n",
      "--------------------------\n",
      "7050th iteration\n",
      "Loss: 0.00034508337201497193\n",
      "--------------------------\n",
      "7060th iteration\n",
      "Loss: 0.0003445938289613385\n",
      "--------------------------\n",
      "7070th iteration\n",
      "Loss: 0.00034410590659666605\n",
      "--------------------------\n",
      "7080th iteration\n",
      "Loss: 0.0003436190989140239\n",
      "--------------------------\n",
      "7090th iteration\n",
      "Loss: 0.00034313390350716527\n",
      "--------------------------\n",
      "7100th iteration\n",
      "Loss: 0.0003426499311396651\n",
      "--------------------------\n",
      "7110th iteration\n",
      "Loss: 0.0003421672553197688\n",
      "--------------------------\n",
      "7120th iteration\n",
      "Loss: 0.0003416862174527592\n",
      "--------------------------\n",
      "7130th iteration\n",
      "Loss: 0.0003412062001483723\n",
      "--------------------------\n",
      "7140th iteration\n",
      "Loss: 0.0003407278125394654\n",
      "--------------------------\n",
      "7150th iteration\n",
      "Loss: 0.0003402507061472317\n",
      "--------------------------\n",
      "7160th iteration\n",
      "Loss: 0.0003397747250263258\n",
      "--------------------------\n",
      "7170th iteration\n",
      "Loss: 0.00033930028498399035\n",
      "--------------------------\n",
      "7180th iteration\n",
      "Loss: 0.0003388269633329894\n",
      "--------------------------\n",
      "7190th iteration\n",
      "Loss: 0.0003383552127082236\n",
      "--------------------------\n",
      "7200th iteration\n",
      "Loss: 0.00033788464935515254\n",
      "--------------------------\n",
      "7210th iteration\n",
      "Loss: 0.00033741538370177205\n",
      "--------------------------\n",
      "7220th iteration\n",
      "Loss: 0.00033694744995936223\n",
      "--------------------------\n",
      "7230th iteration\n",
      "Loss: 0.0003364806179180095\n",
      "--------------------------\n",
      "7240th iteration\n",
      "Loss: 0.0003360155255651672\n",
      "--------------------------\n",
      "7250th iteration\n",
      "Loss: 0.00033555130175902\n",
      "--------------------------\n",
      "7260th iteration\n",
      "Loss: 0.00033508854607525846\n",
      "--------------------------\n",
      "7270th iteration\n",
      "Loss: 0.0003346271416044727\n",
      "--------------------------\n",
      "7280th iteration\n",
      "Loss: 0.0003341665972228228\n",
      "--------------------------\n",
      "7290th iteration\n",
      "Loss: 0.0003337078095186892\n",
      "--------------------------\n",
      "7300th iteration\n",
      "Loss: 0.0003332500627407589\n",
      "--------------------------\n",
      "7310th iteration\n",
      "Loss: 0.00033279346633192285\n",
      "--------------------------\n",
      "7320th iteration\n",
      "Loss: 0.00033233839007121567\n",
      "--------------------------\n",
      "7330th iteration\n",
      "Loss: 0.0003318841593233019\n",
      "--------------------------\n",
      "7340th iteration\n",
      "Loss: 0.00033143166458399675\n",
      "--------------------------\n",
      "7350th iteration\n",
      "Loss: 0.00033098008365126314\n",
      "--------------------------\n",
      "7360th iteration\n",
      "Loss: 0.00033052967400384355\n",
      "--------------------------\n",
      "7370th iteration\n",
      "Loss: 0.0003300807287478863\n",
      "--------------------------\n",
      "7380th iteration\n",
      "Loss: 0.00032963272590865616\n",
      "--------------------------\n",
      "7390th iteration\n",
      "Loss: 0.0003291861802742484\n",
      "--------------------------\n",
      "7400th iteration\n",
      "Loss: 0.0003287407925574736\n",
      "--------------------------\n",
      "7410th iteration\n",
      "Loss: 0.0003282964123901111\n",
      "--------------------------\n",
      "7420th iteration\n",
      "Loss: 0.0003278536257404752\n",
      "--------------------------\n",
      "7430th iteration\n",
      "Loss: 0.0003274116565160873\n",
      "--------------------------\n",
      "7440th iteration\n",
      "Loss: 0.0003269709798261208\n",
      "--------------------------\n",
      "7450th iteration\n",
      "Loss: 0.0003265317019357269\n",
      "--------------------------\n",
      "7460th iteration\n",
      "Loss: 0.0003260932335418156\n",
      "--------------------------\n",
      "7470th iteration\n",
      "Loss: 0.0003256562305079928\n",
      "--------------------------\n",
      "7480th iteration\n",
      "Loss: 0.00032522032370108013\n",
      "--------------------------\n",
      "7490th iteration\n",
      "Loss: 0.00032478547385889647\n",
      "--------------------------\n",
      "7500th iteration\n",
      "Loss: 0.0003243520057592537\n",
      "--------------------------\n",
      "7510th iteration\n",
      "Loss: 0.00032391944305701543\n",
      "--------------------------\n",
      "7520th iteration\n",
      "Loss: 0.0003234881465437722\n",
      "--------------------------\n",
      "7530th iteration\n",
      "Loss: 0.00032305811269695646\n",
      "--------------------------\n",
      "7540th iteration\n",
      "Loss: 0.000322628867532681\n",
      "--------------------------\n",
      "7550th iteration\n",
      "Loss: 0.0003222010961312095\n",
      "--------------------------\n",
      "7560th iteration\n",
      "Loss: 0.00032177436100554505\n",
      "--------------------------\n",
      "7570th iteration\n",
      "Loss: 0.00032134858744717603\n",
      "--------------------------\n",
      "7580th iteration\n",
      "Loss: 0.00032092424112734746\n",
      "--------------------------\n",
      "7590th iteration\n",
      "Loss: 0.000320500886450678\n",
      "--------------------------\n",
      "7600th iteration\n",
      "Loss: 0.0003200785927876537\n",
      "--------------------------\n",
      "7610th iteration\n",
      "Loss: 0.00031965750084424996\n",
      "--------------------------\n",
      "7620th iteration\n",
      "Loss: 0.000319237392471998\n",
      "--------------------------\n",
      "7630th iteration\n",
      "Loss: 0.0003188184798362872\n",
      "--------------------------\n",
      "7640th iteration\n",
      "Loss: 0.0003184007239586901\n",
      "--------------------------\n",
      "7650th iteration\n",
      "Loss: 0.00031798372936951984\n",
      "--------------------------\n",
      "7660th iteration\n",
      "Loss: 0.00031756834945531604\n",
      "--------------------------\n",
      "7670th iteration\n",
      "Loss: 0.0003171537966374811\n",
      "--------------------------\n",
      "7680th iteration\n",
      "Loss: 0.00031674006909336735\n",
      "--------------------------\n",
      "7690th iteration\n",
      "Loss: 0.00031632794564299016\n",
      "--------------------------\n",
      "7700th iteration\n",
      "Loss: 0.00031591657092741284\n",
      "--------------------------\n",
      "7710th iteration\n",
      "Loss: 0.00031550615577102597\n",
      "--------------------------\n",
      "7720th iteration\n",
      "Loss: 0.000315097192660069\n",
      "--------------------------\n",
      "7730th iteration\n",
      "Loss: 0.00031468897133100183\n",
      "--------------------------\n",
      "7740th iteration\n",
      "Loss: 0.000314281772311649\n",
      "--------------------------\n",
      "7750th iteration\n",
      "Loss: 0.0003138758394621552\n",
      "--------------------------\n",
      "7760th iteration\n",
      "Loss: 0.00031347074726975583\n",
      "--------------------------\n",
      "7770th iteration\n",
      "Loss: 0.0003130669152559092\n",
      "--------------------------\n",
      "7780th iteration\n",
      "Loss: 0.0003126640943880775\n",
      "--------------------------\n",
      "7790th iteration\n",
      "Loss: 0.00031226200187526535\n",
      "--------------------------\n",
      "7800th iteration\n",
      "Loss: 0.000311861335896233\n",
      "--------------------------\n",
      "7810th iteration\n",
      "Loss: 0.0003114616031571634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "7820th iteration\n",
      "Loss: 0.000311062592024717\n",
      "--------------------------\n",
      "7830th iteration\n",
      "Loss: 0.00031066496316535367\n",
      "--------------------------\n",
      "7840th iteration\n",
      "Loss: 0.00031026829492938597\n",
      "--------------------------\n",
      "7850th iteration\n",
      "Loss: 0.00030987234161847097\n",
      "--------------------------\n",
      "7860th iteration\n",
      "Loss: 0.00030947783081604314\n",
      "--------------------------\n",
      "7870th iteration\n",
      "Loss: 0.000309084099540726\n",
      "--------------------------\n",
      "7880th iteration\n",
      "Loss: 0.00030869118071674294\n",
      "--------------------------\n",
      "7890th iteration\n",
      "Loss: 0.0003082995912802336\n",
      "--------------------------\n",
      "7900th iteration\n",
      "Loss: 0.0003079088784148256\n",
      "--------------------------\n",
      "7910th iteration\n",
      "Loss: 0.00030751886756968797\n",
      "--------------------------\n",
      "7920th iteration\n",
      "Loss: 0.0003071302808320956\n",
      "--------------------------\n",
      "7930th iteration\n",
      "Loss: 0.0003067425635036584\n",
      "--------------------------\n",
      "7940th iteration\n",
      "Loss: 0.0003063555417097267\n",
      "--------------------------\n",
      "7950th iteration\n",
      "Loss: 0.00030596990049617807\n",
      "--------------------------\n",
      "7960th iteration\n",
      "Loss: 0.00030558505312920853\n",
      "--------------------------\n",
      "7970th iteration\n",
      "Loss: 0.0003052009978340487\n",
      "--------------------------\n",
      "7980th iteration\n",
      "Loss: 0.00030481831412797287\n",
      "--------------------------\n",
      "7990th iteration\n",
      "Loss: 0.00030443631505536477\n",
      "--------------------------\n",
      "8000th iteration\n",
      "Loss: 0.00030405510156073613\n",
      "--------------------------\n",
      "8010th iteration\n",
      "Loss: 0.00030367518287390693\n",
      "--------------------------\n",
      "8020th iteration\n",
      "Loss: 0.0003032961130345845\n",
      "--------------------------\n",
      "8030th iteration\n",
      "Loss: 0.0003029177201518478\n",
      "--------------------------\n",
      "8040th iteration\n",
      "Loss: 0.0003025407155645605\n",
      "--------------------------\n",
      "8050th iteration\n",
      "Loss: 0.00030216445124896815\n",
      "--------------------------\n",
      "8060th iteration\n",
      "Loss: 0.00030178895945684475\n",
      "--------------------------\n",
      "8070th iteration\n",
      "Loss: 0.0003014146780288054\n",
      "--------------------------\n",
      "8080th iteration\n",
      "Loss: 0.00030104119838216193\n",
      "--------------------------\n",
      "8090th iteration\n",
      "Loss: 0.0003006684849499745\n",
      "--------------------------\n",
      "8100th iteration\n",
      "Loss: 0.00030029690659006455\n",
      "--------------------------\n",
      "8110th iteration\n",
      "Loss: 0.00029992629200450933\n",
      "--------------------------\n",
      "8120th iteration\n",
      "Loss: 0.0002995563363312811\n",
      "--------------------------\n",
      "8130th iteration\n",
      "Loss: 0.00029918754168669454\n",
      "--------------------------\n",
      "8140th iteration\n",
      "Loss: 0.00029881956970984595\n",
      "--------------------------\n",
      "8150th iteration\n",
      "Loss: 0.0002984524519405295\n",
      "--------------------------\n",
      "8160th iteration\n",
      "Loss: 0.0002980861529247972\n",
      "--------------------------\n",
      "8170th iteration\n",
      "Loss: 0.0002977210047188538\n",
      "--------------------------\n",
      "8180th iteration\n",
      "Loss: 0.00029735650384698446\n",
      "--------------------------\n",
      "8190th iteration\n",
      "Loss: 0.0002969928822346653\n",
      "--------------------------\n",
      "8200th iteration\n",
      "Loss: 0.00029663043722912035\n",
      "--------------------------\n",
      "8210th iteration\n",
      "Loss: 0.0002962687335506608\n",
      "--------------------------\n",
      "8220th iteration\n",
      "Loss: 0.00029590757041471393\n",
      "--------------------------\n",
      "8230th iteration\n",
      "Loss: 0.000295547808900943\n",
      "--------------------------\n",
      "8240th iteration\n",
      "Loss: 0.0002951887827003485\n",
      "--------------------------\n",
      "8250th iteration\n",
      "Loss: 0.0002948302917659822\n",
      "--------------------------\n",
      "8260th iteration\n",
      "Loss: 0.0002944730619249881\n",
      "--------------------------\n",
      "8270th iteration\n",
      "Loss: 0.00029411669373011223\n",
      "--------------------------\n",
      "8280th iteration\n",
      "Loss: 0.0002937608555765245\n",
      "--------------------------\n",
      "8290th iteration\n",
      "Loss: 0.00029340613901722705\n",
      "--------------------------\n",
      "8300th iteration\n",
      "Loss: 0.00029305231091792603\n",
      "--------------------------\n",
      "8310th iteration\n",
      "Loss: 0.0002926992049166619\n",
      "--------------------------\n",
      "8320th iteration\n",
      "Loss: 0.00029234691782508224\n",
      "--------------------------\n",
      "8330th iteration\n",
      "Loss: 0.00029199570975073727\n",
      "--------------------------\n",
      "8340th iteration\n",
      "Loss: 0.00029164511979897336\n",
      "--------------------------\n",
      "8350th iteration\n",
      "Loss: 0.0002912952447828296\n",
      "--------------------------\n",
      "8360th iteration\n",
      "Loss: 0.0002909466379804698\n",
      "--------------------------\n",
      "8370th iteration\n",
      "Loss: 0.0002905986438735737\n",
      "--------------------------\n",
      "8380th iteration\n",
      "Loss: 0.0002902512612583865\n",
      "--------------------------\n",
      "8390th iteration\n",
      "Loss: 0.00028990497674663193\n",
      "--------------------------\n",
      "8400th iteration\n",
      "Loss: 0.00028955956002805014\n",
      "--------------------------\n",
      "8410th iteration\n",
      "Loss: 0.00028921474943623734\n",
      "--------------------------\n",
      "8420th iteration\n",
      "Loss: 0.0002888707382164568\n",
      "--------------------------\n",
      "8430th iteration\n",
      "Loss: 0.0002885278805173848\n",
      "--------------------------\n",
      "8440th iteration\n",
      "Loss: 0.0002881855266520865\n",
      "--------------------------\n",
      "8450th iteration\n",
      "Loss: 0.00028784386952015724\n",
      "--------------------------\n",
      "8460th iteration\n",
      "Loss: 0.00028750339138421257\n",
      "--------------------------\n",
      "8470th iteration\n",
      "Loss: 0.0002871636702390948\n",
      "--------------------------\n",
      "8480th iteration\n",
      "Loss: 0.00028682444695867925\n",
      "--------------------------\n",
      "8490th iteration\n",
      "Loss: 0.0002864862349172748\n",
      "--------------------------\n",
      "8500th iteration\n",
      "Loss: 0.00028614893518864144\n",
      "--------------------------\n",
      "8510th iteration\n",
      "Loss: 0.0002858122248679116\n",
      "--------------------------\n",
      "8520th iteration\n",
      "Loss: 0.00028547626292807905\n",
      "--------------------------\n",
      "8530th iteration\n",
      "Loss: 0.00028514136753407824\n",
      "--------------------------\n",
      "8540th iteration\n",
      "Loss: 0.00028480715246092213\n",
      "--------------------------\n",
      "8550th iteration\n",
      "Loss: 0.0002844735205056873\n",
      "--------------------------\n",
      "8560th iteration\n",
      "Loss: 0.000284140853030872\n",
      "--------------------------\n",
      "8570th iteration\n",
      "Loss: 0.0002838090202184224\n",
      "--------------------------\n",
      "8580th iteration\n",
      "Loss: 0.0002834777656491743\n",
      "--------------------------\n",
      "8590th iteration\n",
      "Loss: 0.0002831472470160789\n",
      "--------------------------\n",
      "8600th iteration\n",
      "Loss: 0.000282817779913212\n",
      "--------------------------\n",
      "8610th iteration\n",
      "Loss: 0.000282488981288699\n",
      "--------------------------\n",
      "8620th iteration\n",
      "Loss: 0.00028216075474870044\n",
      "--------------------------\n",
      "8630th iteration\n",
      "Loss: 0.00028183347857607514\n",
      "--------------------------\n",
      "8640th iteration\n",
      "Loss: 0.00028150702403291375\n",
      "--------------------------\n",
      "8650th iteration\n",
      "Loss: 0.00028118113680036165\n",
      "--------------------------\n",
      "8660th iteration\n",
      "Loss: 0.00028085581578648003\n",
      "--------------------------\n",
      "8670th iteration\n",
      "Loss: 0.0002805316892893997\n",
      "--------------------------\n",
      "8680th iteration\n",
      "Loss: 0.00028020821966939124\n",
      "--------------------------\n",
      "8690th iteration\n",
      "Loss: 0.0002798853113291796\n",
      "--------------------------\n",
      "8700th iteration\n",
      "Loss: 0.0002795631200002703\n",
      "--------------------------\n",
      "8710th iteration\n",
      "Loss: 0.000279241957302348\n",
      "--------------------------\n",
      "8720th iteration\n",
      "Loss: 0.0002789213512094901\n",
      "--------------------------\n",
      "8730th iteration\n",
      "Loss: 0.00027860130065429336\n",
      "--------------------------\n",
      "8740th iteration\n",
      "Loss: 0.0002782823040424274\n",
      "--------------------------\n",
      "8750th iteration\n",
      "Loss: 0.0002779639844182936\n",
      "--------------------------\n",
      "8760th iteration\n",
      "Loss: 0.0002776462157075651\n",
      "--------------------------\n",
      "8770th iteration\n",
      "Loss: 0.0002773291212974414\n",
      "--------------------------\n",
      "8780th iteration\n",
      "Loss: 0.0002770130726036389\n",
      "--------------------------\n",
      "8790th iteration\n",
      "Loss: 0.00027669757024487455\n",
      "--------------------------\n",
      "8800th iteration\n",
      "Loss: 0.0002763827061801197\n",
      "--------------------------\n",
      "8810th iteration\n",
      "Loss: 0.00027606860293600643\n",
      "--------------------------\n",
      "8820th iteration\n",
      "Loss: 0.0002757553515301236\n",
      "--------------------------\n",
      "8830th iteration\n",
      "Loss: 0.00027544273357298625\n",
      "--------------------------\n",
      "8840th iteration\n",
      "Loss: 0.0002751305625459027\n",
      "--------------------------\n",
      "8850th iteration\n",
      "Loss: 0.0002748194234737853\n",
      "--------------------------\n",
      "8860th iteration\n",
      "Loss: 0.0002745090365063833\n",
      "--------------------------\n",
      "8870th iteration\n",
      "Loss: 0.0002741990923034065\n",
      "--------------------------\n",
      "8880th iteration\n",
      "Loss: 0.0002738898359476562\n",
      "--------------------------\n",
      "8890th iteration\n",
      "Loss: 0.00027358157280588775\n",
      "--------------------------\n",
      "8900th iteration\n",
      "Loss: 0.00027327393243726963\n",
      "--------------------------\n",
      "8910th iteration\n",
      "Loss: 0.0002729667298013725\n",
      "--------------------------\n",
      "8920th iteration\n",
      "Loss: 0.00027266023947721213\n",
      "--------------------------\n",
      "8930th iteration\n",
      "Loss: 0.0002723547959127857\n",
      "--------------------------\n",
      "8940th iteration\n",
      "Loss: 0.000272049786003842\n",
      "--------------------------\n",
      "8950th iteration\n",
      "Loss: 0.00027174530050559165\n",
      "--------------------------\n",
      "8960th iteration\n",
      "Loss: 0.0002714417342710829\n",
      "--------------------------\n",
      "8970th iteration\n",
      "Loss: 0.000271138902492261\n",
      "--------------------------\n",
      "8980th iteration\n",
      "Loss: 0.000270836590786073\n",
      "--------------------------\n",
      "8990th iteration\n",
      "Loss: 0.00027053479816613964\n",
      "--------------------------\n",
      "9000th iteration\n",
      "Loss: 0.0002702340389935513\n",
      "--------------------------\n",
      "9010th iteration\n",
      "Loss: 0.0002699338866443356\n",
      "--------------------------\n",
      "9020th iteration\n",
      "Loss: 0.0002696342490904806\n",
      "--------------------------\n",
      "9030th iteration\n",
      "Loss: 0.00026933512536038754\n",
      "--------------------------\n",
      "9040th iteration\n",
      "Loss: 0.0002690369068273535\n",
      "--------------------------\n",
      "9050th iteration\n",
      "Loss: 0.00026873941033251096\n",
      "--------------------------\n",
      "9060th iteration\n",
      "Loss: 0.0002684424234142569\n",
      "--------------------------\n",
      "9070th iteration\n",
      "Loss: 0.00026814594511560623\n",
      "--------------------------\n",
      "9080th iteration\n",
      "Loss: 0.0002678504251838798\n",
      "--------------------------\n",
      "9090th iteration\n",
      "Loss: 0.00026755556102575883\n",
      "--------------------------\n",
      "9100th iteration\n",
      "Loss: 0.00026726111134876276\n",
      "--------------------------\n",
      "9110th iteration\n",
      "Loss: 0.00026696716534131145\n",
      "--------------------------\n",
      "9120th iteration\n",
      "Loss: 0.00026667441009958656\n",
      "--------------------------\n",
      "9130th iteration\n",
      "Loss: 0.0002663820654790797\n",
      "--------------------------\n",
      "9140th iteration\n",
      "Loss: 0.0002660902203744112\n",
      "--------------------------\n",
      "9150th iteration\n",
      "Loss: 0.00026579887385149\n",
      "--------------------------\n",
      "9160th iteration\n",
      "Loss: 0.00026550853130665353\n",
      "--------------------------\n",
      "9170th iteration\n",
      "Loss: 0.00026521877361542265\n",
      "--------------------------\n",
      "9180th iteration\n",
      "Loss: 0.000264929510395701\n",
      "--------------------------\n",
      "9190th iteration\n",
      "Loss: 0.0002646406516674846\n",
      "--------------------------\n",
      "9200th iteration\n",
      "Loss: 0.0002643528788468789\n",
      "--------------------------\n",
      "9210th iteration\n",
      "Loss: 0.00026406559662800065\n",
      "--------------------------\n",
      "9220th iteration\n",
      "Loss: 0.00026377880408570903\n",
      "--------------------------\n",
      "9230th iteration\n",
      "Loss: 0.0002634925003078901\n",
      "--------------------------\n",
      "9240th iteration\n",
      "Loss: 0.0002632072749017476\n",
      "--------------------------\n",
      "9250th iteration\n",
      "Loss: 0.0002629224466739487\n",
      "--------------------------\n",
      "9260th iteration\n",
      "Loss: 0.0002626381917636005\n",
      "--------------------------\n",
      "9270th iteration\n",
      "Loss: 0.00026235433240786676\n",
      "--------------------------\n",
      "9280th iteration\n",
      "Loss: 0.0002620714853578958\n",
      "--------------------------\n",
      "9290th iteration\n",
      "Loss: 0.0002617891781271002\n",
      "--------------------------\n",
      "9300th iteration\n",
      "Loss: 0.00026150726294991625\n",
      "--------------------------\n",
      "9310th iteration\n",
      "Loss: 0.00026122591503256466\n",
      "--------------------------\n",
      "9320th iteration\n",
      "Loss: 0.00026094542593216335\n",
      "--------------------------\n",
      "9330th iteration\n",
      "Loss: 0.0002606655303591246\n",
      "--------------------------\n",
      "9340th iteration\n",
      "Loss: 0.00026038611020390084\n",
      "--------------------------\n",
      "9350th iteration\n",
      "Loss: 0.00026010716458385656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "9360th iteration\n",
      "Loss: 0.0002598291006817168\n",
      "--------------------------\n",
      "9370th iteration\n",
      "Loss: 0.00025955159603296664\n",
      "--------------------------\n",
      "9380th iteration\n",
      "Loss: 0.00025927456221659976\n",
      "--------------------------\n",
      "9390th iteration\n",
      "Loss: 0.0002589979983575662\n",
      "--------------------------\n",
      "9400th iteration\n",
      "Loss: 0.00025872219382030293\n",
      "--------------------------\n",
      "9410th iteration\n",
      "Loss: 0.0002584471468061735\n",
      "--------------------------\n",
      "9420th iteration\n",
      "Loss: 0.00025817247902350975\n",
      "--------------------------\n",
      "9430th iteration\n",
      "Loss: 0.0002578982766713291\n",
      "--------------------------\n",
      "9440th iteration\n",
      "Loss: 0.00025762465449291985\n",
      "--------------------------\n",
      "9450th iteration\n",
      "Loss: 0.000257351871087098\n",
      "--------------------------\n",
      "9460th iteration\n",
      "Loss: 0.0002570796360052407\n",
      "--------------------------\n",
      "9470th iteration\n",
      "Loss: 0.0002568077752729294\n",
      "--------------------------\n",
      "9480th iteration\n",
      "Loss: 0.0002565363746466435\n",
      "--------------------------\n",
      "9490th iteration\n",
      "Loss: 0.0002562660082247849\n",
      "--------------------------\n",
      "9500th iteration\n",
      "Loss: 0.000255996012847892\n",
      "--------------------------\n",
      "9510th iteration\n",
      "Loss: 0.00025572647399604463\n",
      "--------------------------\n",
      "9520th iteration\n",
      "Loss: 0.00025545739082889193\n",
      "--------------------------\n",
      "9530th iteration\n",
      "Loss: 0.00025518916328347584\n",
      "--------------------------\n",
      "9540th iteration\n",
      "Loss: 0.0002549214746965512\n",
      "--------------------------\n",
      "9550th iteration\n",
      "Loss: 0.0002546542382550278\n",
      "--------------------------\n",
      "9560th iteration\n",
      "Loss: 0.0002543874531253344\n",
      "--------------------------\n",
      "9570th iteration\n",
      "Loss: 0.00025412134653787663\n",
      "--------------------------\n",
      "9580th iteration\n",
      "Loss: 0.0002538559454265647\n",
      "--------------------------\n",
      "9590th iteration\n",
      "Loss: 0.0002535909921290031\n",
      "--------------------------\n",
      "9600th iteration\n",
      "Loss: 0.0002533264858189\n",
      "--------------------------\n",
      "9610th iteration\n",
      "Loss: 0.0002530623405177006\n",
      "--------------------------\n",
      "9620th iteration\n",
      "Loss: 0.00025279920791830763\n",
      "--------------------------\n",
      "9630th iteration\n",
      "Loss: 0.00025253651884822885\n",
      "--------------------------\n",
      "9640th iteration\n",
      "Loss: 0.00025227427248784075\n",
      "--------------------------\n",
      "9650th iteration\n",
      "Loss: 0.00025201238321998816\n",
      "--------------------------\n",
      "9660th iteration\n",
      "Loss: 0.00025175127411501284\n",
      "--------------------------\n",
      "9670th iteration\n",
      "Loss: 0.0002514907458310842\n",
      "--------------------------\n",
      "9680th iteration\n",
      "Loss: 0.0002512307407466124\n",
      "--------------------------\n",
      "9690th iteration\n",
      "Loss: 0.0002509710888815795\n",
      "--------------------------\n",
      "9700th iteration\n",
      "Loss: 0.00025071184594890053\n",
      "--------------------------\n",
      "9710th iteration\n",
      "Loss: 0.0002504536293346471\n",
      "--------------------------\n",
      "9720th iteration\n",
      "Loss: 0.0002501957628201113\n",
      "--------------------------\n",
      "9730th iteration\n",
      "Loss: 0.0002499382458690294\n",
      "--------------------------\n",
      "9740th iteration\n",
      "Loss: 0.00024968124599780863\n",
      "--------------------------\n",
      "9750th iteration\n",
      "Loss: 0.0002494249300468897\n",
      "--------------------------\n",
      "9760th iteration\n",
      "Loss: 0.0002491691846464109\n",
      "--------------------------\n",
      "9770th iteration\n",
      "Loss: 0.00024891395272440427\n",
      "--------------------------\n",
      "9780th iteration\n",
      "Loss: 0.00024865906588044496\n",
      "--------------------------\n",
      "9790th iteration\n",
      "Loss: 0.0002484045793245542\n",
      "--------------------------\n",
      "9800th iteration\n",
      "Loss: 0.0002481510212687079\n",
      "--------------------------\n",
      "9810th iteration\n",
      "Loss: 0.0002478978888385983\n",
      "--------------------------\n",
      "9820th iteration\n",
      "Loss: 0.00024764518125449525\n",
      "--------------------------\n",
      "9830th iteration\n",
      "Loss: 0.00024739281449281524\n",
      "--------------------------\n",
      "9840th iteration\n",
      "Loss: 0.00024714114844966823\n",
      "--------------------------\n",
      "9850th iteration\n",
      "Loss: 0.0002468900984241984\n",
      "--------------------------\n",
      "9860th iteration\n",
      "Loss: 0.0002466394693785741\n",
      "--------------------------\n",
      "9870th iteration\n",
      "Loss: 0.0002463892605457602\n",
      "--------------------------\n",
      "9880th iteration\n",
      "Loss: 0.0002461393883357139\n",
      "--------------------------\n",
      "9890th iteration\n",
      "Loss: 0.000245890431495766\n",
      "--------------------------\n",
      "9900th iteration\n",
      "Loss: 0.0002456419468652951\n",
      "--------------------------\n",
      "9910th iteration\n",
      "Loss: 0.00024539379587995124\n",
      "--------------------------\n",
      "9920th iteration\n",
      "Loss: 0.00024514606053435315\n",
      "--------------------------\n",
      "9930th iteration\n",
      "Loss: 0.00024489876755516126\n",
      "--------------------------\n",
      "9940th iteration\n",
      "Loss: 0.00024465232777773924\n",
      "--------------------------\n",
      "9950th iteration\n",
      "Loss: 0.00024440621820209503\n",
      "--------------------------\n",
      "9960th iteration\n",
      "Loss: 0.00024416052049188076\n",
      "--------------------------\n",
      "9970th iteration\n",
      "Loss: 0.00024391523390511743\n",
      "--------------------------\n",
      "9980th iteration\n",
      "Loss: 0.00024367054904879913\n",
      "--------------------------\n",
      "9990th iteration\n",
      "Loss: 0.0002434265465264855\n",
      "--------------------------\n",
      "10000th iteration\n",
      "Loss: 0.00024318295197356713\n",
      "--------------------------\n",
      "10010th iteration\n",
      "Loss: 0.0002429396828980729\n",
      "--------------------------\n",
      "10020th iteration\n",
      "Loss: 0.00024269673881333726\n",
      "--------------------------\n",
      "10030th iteration\n",
      "Loss: 0.0002424547175932027\n",
      "--------------------------\n",
      "10040th iteration\n",
      "Loss: 0.00024221304636972915\n",
      "--------------------------\n",
      "10050th iteration\n",
      "Loss: 0.0002419718602854809\n",
      "--------------------------\n",
      "10060th iteration\n",
      "Loss: 0.0002417309956739767\n",
      "--------------------------\n",
      "10070th iteration\n",
      "Loss: 0.00024149045205716408\n",
      "--------------------------\n",
      "10080th iteration\n",
      "Loss: 0.00024125085140785335\n",
      "--------------------------\n",
      "10090th iteration\n",
      "Loss: 0.00024101156955736976\n",
      "--------------------------\n",
      "10100th iteration\n",
      "Loss: 0.0002407727680727341\n",
      "--------------------------\n",
      "10110th iteration\n",
      "Loss: 0.00024053420316157316\n",
      "--------------------------\n",
      "10120th iteration\n",
      "Loss: 0.00024029603632488378\n",
      "--------------------------\n",
      "10130th iteration\n",
      "Loss: 0.0002400582668631864\n",
      "--------------------------\n",
      "10140th iteration\n",
      "Loss: 0.00023982081337045835\n",
      "--------------------------\n",
      "10150th iteration\n",
      "Loss: 0.00023958461593863006\n",
      "--------------------------\n",
      "10160th iteration\n",
      "Loss: 0.00023934894645534328\n",
      "--------------------------\n",
      "10170th iteration\n",
      "Loss: 0.00023911366971721888\n",
      "--------------------------\n",
      "10180th iteration\n",
      "Loss: 0.00023887870461472137\n",
      "--------------------------\n",
      "10190th iteration\n",
      "Loss: 0.00023864413098201263\n",
      "--------------------------\n",
      "10200th iteration\n",
      "Loss: 0.00023840986788604523\n",
      "--------------------------\n",
      "10210th iteration\n",
      "Loss: 0.00023817599501471087\n",
      "--------------------------\n",
      "10220th iteration\n",
      "Loss: 0.00023794251168058692\n",
      "--------------------------\n",
      "10230th iteration\n",
      "Loss: 0.00023770933720630407\n",
      "--------------------------\n",
      "10240th iteration\n",
      "Loss: 0.00023747647114487027\n",
      "--------------------------\n",
      "10250th iteration\n",
      "Loss: 0.0002372449508782867\n",
      "--------------------------\n",
      "10260th iteration\n",
      "Loss: 0.00023701384242996238\n",
      "--------------------------\n",
      "10270th iteration\n",
      "Loss: 0.000236783118467394\n",
      "--------------------------\n",
      "10280th iteration\n",
      "Loss: 0.00023655277828572038\n",
      "--------------------------\n",
      "10290th iteration\n",
      "Loss: 0.00023632274166741514\n",
      "--------------------------\n",
      "10300th iteration\n",
      "Loss: 0.00023609300815999242\n",
      "--------------------------\n",
      "10310th iteration\n",
      "Loss: 0.00023586365668519114\n",
      "--------------------------\n",
      "10320th iteration\n",
      "Loss: 0.00023563468657322799\n",
      "--------------------------\n",
      "10330th iteration\n",
      "Loss: 0.00023540593871655073\n",
      "--------------------------\n",
      "10340th iteration\n",
      "Loss: 0.00023517765035383517\n",
      "--------------------------\n",
      "10350th iteration\n",
      "Loss: 0.0002349504266966731\n",
      "--------------------------\n",
      "10360th iteration\n",
      "Loss: 0.00023472387019171198\n",
      "--------------------------\n",
      "10370th iteration\n",
      "Loss: 0.00023449753213493363\n",
      "--------------------------\n",
      "10380th iteration\n",
      "Loss: 0.0002342716488132235\n",
      "--------------------------\n",
      "10390th iteration\n",
      "Loss: 0.0002340459830455666\n",
      "--------------------------\n",
      "10400th iteration\n",
      "Loss: 0.0002338207706621408\n",
      "--------------------------\n",
      "10410th iteration\n",
      "Loss: 0.0002335957749570528\n",
      "--------------------------\n",
      "10420th iteration\n",
      "Loss: 0.00023337123131990877\n",
      "--------------------------\n",
      "10430th iteration\n",
      "Loss: 0.0002331469035034957\n",
      "--------------------------\n",
      "10440th iteration\n",
      "Loss: 0.00023292294808147684\n",
      "--------------------------\n",
      "10450th iteration\n",
      "Loss: 0.00023269980813243565\n",
      "--------------------------\n",
      "10460th iteration\n",
      "Loss: 0.0002324775599686822\n",
      "--------------------------\n",
      "10470th iteration\n",
      "Loss: 0.0002322556022237908\n",
      "--------------------------\n",
      "10480th iteration\n",
      "Loss: 0.00023203401253852083\n",
      "--------------------------\n",
      "10490th iteration\n",
      "Loss: 0.00023181271224452174\n",
      "--------------------------\n",
      "10500th iteration\n",
      "Loss: 0.00023159177884127672\n",
      "--------------------------\n",
      "10510th iteration\n",
      "Loss: 0.0002313711338252634\n",
      "--------------------------\n",
      "10520th iteration\n",
      "Loss: 0.0002311508545600485\n",
      "--------------------------\n",
      "10530th iteration\n",
      "Loss: 0.00023093086270135568\n",
      "--------------------------\n",
      "10540th iteration\n",
      "Loss: 0.00023071115783759212\n",
      "--------------------------\n",
      "10550th iteration\n",
      "Loss: 0.0002304918171353515\n",
      "--------------------------\n",
      "10560th iteration\n",
      "Loss: 0.0002302737956495801\n",
      "--------------------------\n",
      "10570th iteration\n",
      "Loss: 0.00023005605781536905\n",
      "--------------------------\n",
      "10580th iteration\n",
      "Loss: 0.00022983868054526752\n",
      "--------------------------\n",
      "10590th iteration\n",
      "Loss: 0.00022962166318652507\n",
      "--------------------------\n",
      "10600th iteration\n",
      "Loss: 0.00022940492790353217\n",
      "--------------------------\n",
      "10610th iteration\n",
      "Loss: 0.00022918847428195113\n",
      "--------------------------\n",
      "10620th iteration\n",
      "Loss: 0.0002289723789598845\n",
      "--------------------------\n",
      "10630th iteration\n",
      "Loss: 0.0002287565643383305\n",
      "--------------------------\n",
      "10640th iteration\n",
      "Loss: 0.00022854103001489407\n",
      "--------------------------\n",
      "10650th iteration\n",
      "Loss: 0.0002283258524325072\n",
      "--------------------------\n",
      "10660th iteration\n",
      "Loss: 0.00022811126126344344\n",
      "--------------------------\n",
      "10670th iteration\n",
      "Loss: 0.00022789766425439928\n",
      "--------------------------\n",
      "10680th iteration\n",
      "Loss: 0.0002276844204967267\n",
      "--------------------------\n",
      "10690th iteration\n",
      "Loss: 0.00022747152934895362\n",
      "--------------------------\n",
      "10700th iteration\n",
      "Loss: 0.0002272588372365376\n",
      "--------------------------\n",
      "10710th iteration\n",
      "Loss: 0.00022704657316881597\n",
      "--------------------------\n",
      "10720th iteration\n",
      "Loss: 0.00022683450732908752\n",
      "--------------------------\n",
      "10730th iteration\n",
      "Loss: 0.00022662279204777649\n",
      "--------------------------\n",
      "10740th iteration\n",
      "Loss: 0.00022641135053233247\n",
      "--------------------------\n",
      "10750th iteration\n",
      "Loss: 0.00022620025851459902\n",
      "--------------------------\n",
      "10760th iteration\n",
      "Loss: 0.0002259894393515545\n",
      "--------------------------\n",
      "10770th iteration\n",
      "Loss: 0.00022577929787296014\n",
      "--------------------------\n",
      "10780th iteration\n",
      "Loss: 0.0002255701108913413\n",
      "--------------------------\n",
      "10790th iteration\n",
      "Loss: 0.00022536119355950733\n",
      "--------------------------\n",
      "10800th iteration\n",
      "Loss: 0.00022515254547534968\n",
      "--------------------------\n",
      "10810th iteration\n",
      "Loss: 0.00022494424193137538\n",
      "--------------------------\n",
      "10820th iteration\n",
      "Loss: 0.00022473620669743896\n",
      "--------------------------\n",
      "10830th iteration\n",
      "Loss: 0.00022452851493495832\n",
      "--------------------------\n",
      "10840th iteration\n",
      "Loss: 0.00022432101508365263\n",
      "--------------------------\n",
      "10850th iteration\n",
      "Loss: 0.00022411393321284878\n",
      "--------------------------\n",
      "10860th iteration\n",
      "Loss: 0.00022390704249274565\n",
      "--------------------------\n",
      "10870th iteration\n",
      "Loss: 0.0002237004933162734\n",
      "--------------------------\n",
      "10880th iteration\n",
      "Loss: 0.00022349441045195207\n",
      "--------------------------\n",
      "10890th iteration\n",
      "Loss: 0.00022328939408509978\n",
      "--------------------------\n",
      "10900th iteration\n",
      "Loss: 0.0002230847159365391\n",
      "--------------------------\n",
      "10910th iteration\n",
      "Loss: 0.00022288030039692728\n",
      "--------------------------\n",
      "10920th iteration\n",
      "Loss: 0.00022267614707860206\n",
      "--------------------------\n",
      "10930th iteration\n",
      "Loss: 0.00022247233045623598\n",
      "--------------------------\n",
      "10940th iteration\n",
      "Loss: 0.00022226877515126871\n",
      "--------------------------\n",
      "10950th iteration\n",
      "Loss: 0.00022206555551155922\n",
      "--------------------------\n",
      "10960th iteration\n",
      "Loss: 0.00022186259630749532\n",
      "--------------------------\n",
      "10970th iteration\n",
      "Loss: 0.00022165989717168902\n",
      "--------------------------\n",
      "10980th iteration\n",
      "Loss: 0.00022145745773955708\n",
      "--------------------------\n",
      "10990th iteration\n",
      "Loss: 0.00022125535211535644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "11000th iteration\n",
      "Loss: 0.00022105422440642355\n",
      "--------------------------\n",
      "11010th iteration\n",
      "Loss: 0.0002208536263784835\n",
      "--------------------------\n",
      "11020th iteration\n",
      "Loss: 0.00022065335888851674\n",
      "--------------------------\n",
      "11030th iteration\n",
      "Loss: 0.0002204533471659974\n",
      "--------------------------\n",
      "11040th iteration\n",
      "Loss: 0.00022025359083737586\n",
      "--------------------------\n",
      "11050th iteration\n",
      "Loss: 0.00022005416357853192\n",
      "--------------------------\n",
      "11060th iteration\n",
      "Loss: 0.00021985491686266095\n",
      "--------------------------\n",
      "11070th iteration\n",
      "Loss: 0.00021965607226734997\n",
      "--------------------------\n",
      "11080th iteration\n",
      "Loss: 0.00021945740749393535\n",
      "--------------------------\n",
      "11090th iteration\n",
      "Loss: 0.00021925899616609558\n",
      "--------------------------\n",
      "11100th iteration\n",
      "Loss: 0.0002190609116546556\n",
      "--------------------------\n",
      "11110th iteration\n",
      "Loss: 0.00021886327616095974\n",
      "--------------------------\n",
      "11120th iteration\n",
      "Loss: 0.00021866667746940993\n",
      "--------------------------\n",
      "11130th iteration\n",
      "Loss: 0.00021847040242622444\n",
      "--------------------------\n",
      "11140th iteration\n",
      "Loss: 0.0002182743770025941\n",
      "--------------------------\n",
      "11150th iteration\n",
      "Loss: 0.0002180786008335267\n",
      "--------------------------\n",
      "11160th iteration\n",
      "Loss: 0.00021788314687232478\n",
      "--------------------------\n",
      "11170th iteration\n",
      "Loss: 0.0002176879413122174\n",
      "--------------------------\n",
      "11180th iteration\n",
      "Loss: 0.00021749298379909927\n",
      "--------------------------\n",
      "11190th iteration\n",
      "Loss: 0.0002172982739823088\n",
      "--------------------------\n",
      "11200th iteration\n",
      "Loss: 0.00021710388457223465\n",
      "--------------------------\n",
      "11210th iteration\n",
      "Loss: 0.00021690974204109585\n",
      "--------------------------\n",
      "11220th iteration\n",
      "Loss: 0.00021671584604917313\n",
      "--------------------------\n",
      "11230th iteration\n",
      "Loss: 0.00021652258485601548\n",
      "--------------------------\n",
      "11240th iteration\n",
      "Loss: 0.00021633015120635878\n",
      "--------------------------\n",
      "11250th iteration\n",
      "Loss: 0.00021613803405997277\n",
      "--------------------------\n",
      "11260th iteration\n",
      "Loss: 0.00021594616018758526\n",
      "--------------------------\n",
      "11270th iteration\n",
      "Loss: 0.00021575452923514992\n",
      "--------------------------\n",
      "11280th iteration\n",
      "Loss: 0.00021556321338529107\n",
      "--------------------------\n",
      "11290th iteration\n",
      "Loss: 0.00021537213962627785\n",
      "--------------------------\n",
      "11300th iteration\n",
      "Loss: 0.00021518130761489525\n",
      "--------------------------\n",
      "11310th iteration\n",
      "Loss: 0.00021499071701109408\n",
      "--------------------------\n",
      "11320th iteration\n",
      "Loss: 0.0002148004397597473\n",
      "--------------------------\n",
      "11330th iteration\n",
      "Loss: 0.00021461040312270138\n",
      "--------------------------\n",
      "11340th iteration\n",
      "Loss: 0.00021442053460746973\n",
      "--------------------------\n",
      "11350th iteration\n",
      "Loss: 0.0002142311705163776\n",
      "--------------------------\n",
      "11360th iteration\n",
      "Loss: 0.00021404288604665457\n",
      "--------------------------\n",
      "11370th iteration\n",
      "Loss: 0.00021385476706032658\n",
      "--------------------------\n",
      "11380th iteration\n",
      "Loss: 0.00021366695721043705\n",
      "--------------------------\n",
      "11390th iteration\n",
      "Loss: 0.0002134793841196855\n",
      "--------------------------\n",
      "11400th iteration\n",
      "Loss: 0.00021329211921775526\n",
      "--------------------------\n",
      "11410th iteration\n",
      "Loss: 0.00021310501856205196\n",
      "--------------------------\n",
      "11420th iteration\n",
      "Loss: 0.00021291822529706219\n",
      "--------------------------\n",
      "11430th iteration\n",
      "Loss: 0.0002127316673225092\n",
      "--------------------------\n",
      "11440th iteration\n",
      "Loss: 0.00021254534431109466\n",
      "--------------------------\n",
      "11450th iteration\n",
      "Loss: 0.0002123592559385751\n",
      "--------------------------\n",
      "11460th iteration\n",
      "Loss: 0.0002121734732885272\n",
      "--------------------------\n",
      "11470th iteration\n",
      "Loss: 0.0002119878531735843\n",
      "--------------------------\n",
      "11480th iteration\n",
      "Loss: 0.00021180329828444477\n",
      "--------------------------\n",
      "11490th iteration\n",
      "Loss: 0.00021161916519534728\n",
      "--------------------------\n",
      "11500th iteration\n",
      "Loss: 0.0002114352633378969\n",
      "--------------------------\n",
      "11510th iteration\n",
      "Loss: 0.0002112516634621383\n",
      "--------------------------\n",
      "11520th iteration\n",
      "Loss: 0.00021106829402197915\n",
      "--------------------------\n",
      "11530th iteration\n",
      "Loss: 0.00021088515468951322\n",
      "--------------------------\n",
      "11540th iteration\n",
      "Loss: 0.00021070224513977797\n",
      "--------------------------\n",
      "11550th iteration\n",
      "Loss: 0.00021051956505039379\n",
      "--------------------------\n",
      "11560th iteration\n",
      "Loss: 0.00021033718488080446\n",
      "--------------------------\n",
      "11570th iteration\n",
      "Loss: 0.00021015496269711104\n",
      "--------------------------\n",
      "11580th iteration\n",
      "Loss: 0.00020997303968637627\n",
      "--------------------------\n",
      "11590th iteration\n",
      "Loss: 0.0002097913447605879\n",
      "--------------------------\n",
      "11600th iteration\n",
      "Loss: 0.00020961006570851908\n",
      "--------------------------\n",
      "11610th iteration\n",
      "Loss: 0.0002094297655314661\n",
      "--------------------------\n",
      "11620th iteration\n",
      "Loss: 0.00020924969087401083\n",
      "--------------------------\n",
      "11630th iteration\n",
      "Loss: 0.0002090699117608734\n",
      "--------------------------\n",
      "11640th iteration\n",
      "Loss: 0.00020889035738728734\n",
      "--------------------------\n",
      "11650th iteration\n",
      "Loss: 0.00020871102743273657\n",
      "--------------------------\n",
      "11660th iteration\n",
      "Loss: 0.0002085319215797322\n",
      "--------------------------\n",
      "11670th iteration\n",
      "Loss: 0.00020835303951317373\n",
      "--------------------------\n",
      "11680th iteration\n",
      "Loss: 0.00020817445096975954\n",
      "--------------------------\n",
      "11690th iteration\n",
      "Loss: 0.00020799601548341816\n",
      "--------------------------\n",
      "11700th iteration\n",
      "Loss: 0.0002078178727890524\n",
      "--------------------------\n",
      "11710th iteration\n",
      "Loss: 0.0002076399525357316\n",
      "--------------------------\n",
      "11720th iteration\n",
      "Loss: 0.00020746225442437946\n",
      "--------------------------\n",
      "11730th iteration\n",
      "Loss: 0.00020728496416787013\n",
      "--------------------------\n",
      "11740th iteration\n",
      "Loss: 0.000207108638542461\n",
      "--------------------------\n",
      "11750th iteration\n",
      "Loss: 0.00020693260219632715\n",
      "--------------------------\n",
      "11760th iteration\n",
      "Loss: 0.00020675671547318048\n",
      "--------------------------\n",
      "11770th iteration\n",
      "Loss: 0.00020658111727190102\n",
      "--------------------------\n",
      "11780th iteration\n",
      "Loss: 0.0002064057376445211\n",
      "--------------------------\n",
      "11790th iteration\n",
      "Loss: 0.00020623057628305248\n",
      "--------------------------\n",
      "11800th iteration\n",
      "Loss: 0.00020605563288233982\n",
      "--------------------------\n",
      "11810th iteration\n",
      "Loss: 0.00020588097641695204\n",
      "--------------------------\n",
      "11820th iteration\n",
      "Loss: 0.00020570646797541035\n",
      "--------------------------\n",
      "11830th iteration\n",
      "Loss: 0.00020553224575982964\n",
      "--------------------------\n",
      "11840th iteration\n",
      "Loss: 0.0002053582402008263\n",
      "--------------------------\n",
      "11850th iteration\n",
      "Loss: 0.00020518438195381102\n",
      "--------------------------\n",
      "11860th iteration\n",
      "Loss: 0.00020501080889502398\n",
      "--------------------------\n",
      "11870th iteration\n",
      "Loss: 0.00020483837069273003\n",
      "--------------------------\n",
      "11880th iteration\n",
      "Loss: 0.0002046661464219652\n",
      "--------------------------\n",
      "11890th iteration\n",
      "Loss: 0.000204494135773994\n",
      "--------------------------\n",
      "11900th iteration\n",
      "Loss: 0.0002043224071966802\n",
      "--------------------------\n",
      "11910th iteration\n",
      "Loss: 0.00020415082281874372\n",
      "--------------------------\n",
      "11920th iteration\n",
      "Loss: 0.00020397951978980212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PyDojoML/dojo/linear/LogisticRegression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mn_iters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PyDojoML/dojo/linear/LogisticRegression.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
