{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dojo.linear import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    ")\n",
    "\n",
    "from dojo.split import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(100_000, 100)\n",
    "y = X @ np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Fitting...\n",
      "The model has been fitted successfully!\n",
      "-----------------------------------------\n",
      "CPU times: user 422 ms, sys: 112 ms, total: 533 ms\n",
      "Wall time: 374 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "    intercept=4.59273776128033e-10,\n",
       "    coefs=[0.08073165 0.9810491  0.1569708  0.72456807 0.42965585 0.38979083\n",
       " 0.42334476 0.5579234  0.02599155 0.4246094  0.25179365 0.13754033\n",
       " 0.14724824 0.48267904 0.6414932  0.07031164 0.74831855 0.46889588\n",
       " 0.89369005 0.09243213 0.48507074 0.517864   0.00411314 0.02177908\n",
       " 0.5349613  0.19123192 0.02819916 0.49660584 0.3954257  0.39477336\n",
       " 0.27532917 0.9272385  0.29024145 0.8724242  0.25758564 0.39538544\n",
       " 0.83265907 0.6100347  0.9264205  0.6005545  0.24283242 0.5230931\n",
       " 0.53486955 0.8458581  0.2009355  0.08464237 0.9240003  0.96217763\n",
       " 0.12686594 0.44398567 0.34750798 0.294777   0.8532942  0.20184024\n",
       " 0.56054527 0.01542707 0.08416628 0.5911836  0.8084852  0.08463167\n",
       " 0.40073553 0.42075065 0.61327875 0.18781863 0.48604402 0.5100247\n",
       " 0.6153396  0.22102174 0.5593576  0.20877966 0.63577855 0.38856485\n",
       " 0.48929125 0.6964154  0.5561242  0.3293797  0.06721611 0.91966796\n",
       " 0.83564687 0.9198865  0.593987   0.8828991  0.2874839  0.02926432\n",
       " 0.4190223  0.39821813 0.8085623  0.55010945 0.8034693  0.50651985\n",
       " 0.59367293 0.08331338 0.93732256 0.9542     0.4401863  0.09012131\n",
       " 0.07279256 0.78775775 0.4573172  0.8043315 ],\n",
       "    verbose=True,\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time linear_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1828640067956284e-13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_scores': array([2.36683347e-13, 2.36338633e-13, 2.36502395e-13, 2.36495069e-13,\n",
       "        2.36883449e-13, 2.36979096e-13, 2.37360525e-13, 2.36424375e-13,\n",
       "        2.36044961e-13, 2.37444370e-13]),\n",
       " 'test_scores': array([2.37422015e-13, 2.41528886e-13, 2.39050557e-13, 2.38516162e-13,\n",
       "        2.35001640e-13, 2.31602337e-13, 2.30199215e-13, 2.39072828e-13,\n",
       "        2.41850984e-13, 2.33121522e-13])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.verbose = False\n",
    "cross_validate(linear_reg, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(alpha=7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "    alpha=7,\n",
       "    loss=<dojo.losses.CrossEntropy object at 0x103d31940>,\n",
       "    regularizer=<dojo.regularizers.L2 object at 0x103d319b0>,\n",
       "    verbose=True,\n",
       "    intercept=0,\n",
       "    coefs=[],\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[1, 1],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 0]]\n",
    ")\n",
    "\n",
    "y = np.array([1 if x[0] and x[1] else 0 for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "10th iteration\n",
      "Loss: 0.2035867409220567\n",
      "--------------------------\n",
      "20th iteration\n",
      "Loss: 0.10892329504855713\n",
      "--------------------------\n",
      "30th iteration\n",
      "Loss: 0.08116938517885197\n",
      "--------------------------\n",
      "40th iteration\n",
      "Loss: 0.06594577732342094\n",
      "--------------------------\n",
      "50th iteration\n",
      "Loss: 0.05649696864786113\n",
      "--------------------------\n",
      "60th iteration\n",
      "Loss: 0.05015756105252146\n",
      "--------------------------\n",
      "70th iteration\n",
      "Loss: 0.04566891672203546\n",
      "--------------------------\n",
      "80th iteration\n",
      "Loss: 0.04236250536978306\n",
      "--------------------------\n",
      "90th iteration\n",
      "Loss: 0.03985217421107226\n",
      "--------------------------\n",
      "100th iteration\n",
      "Loss: 0.037900217982854124\n",
      "--------------------------\n",
      "110th iteration\n",
      "Loss: 0.036352878622072676\n",
      "--------------------------\n",
      "120th iteration\n",
      "Loss: 0.03510663639547598\n",
      "--------------------------\n",
      "130th iteration\n",
      "Loss: 0.03408944401180428\n",
      "--------------------------\n",
      "140th iteration\n",
      "Loss: 0.03324976963212996\n",
      "--------------------------\n",
      "150th iteration\n",
      "Loss: 0.03254987364663656\n",
      "--------------------------\n",
      "160th iteration\n",
      "Loss: 0.031961557813358035\n",
      "--------------------------\n",
      "170th iteration\n",
      "Loss: 0.03146338022212956\n",
      "--------------------------\n",
      "180th iteration\n",
      "Loss: 0.031038782214453938\n",
      "--------------------------\n",
      "190th iteration\n",
      "Loss: 0.030674814186049577\n",
      "--------------------------\n",
      "200th iteration\n",
      "Loss: 0.030361210492270186\n",
      "--------------------------\n",
      "210th iteration\n",
      "Loss: 0.03008975483827659\n",
      "--------------------------\n",
      "220th iteration\n",
      "Loss: 0.029853805842716387\n",
      "--------------------------\n",
      "230th iteration\n",
      "Loss: 0.029647946112400757\n",
      "--------------------------\n",
      "240th iteration\n",
      "Loss: 0.029467725433402404\n",
      "--------------------------\n",
      "250th iteration\n",
      "Loss: 0.029309459378255482\n",
      "--------------------------\n",
      "260th iteration\n",
      "Loss: 0.029170075352471517\n",
      "--------------------------\n",
      "270th iteration\n",
      "Loss: 0.02904700104683909\n",
      "--------------------------\n",
      "280th iteration\n",
      "Loss: 0.028938065126051835\n",
      "--------------------------\n",
      "290th iteration\n",
      "Loss: 0.028841433651511345\n",
      "--------------------------\n",
      "300th iteration\n",
      "Loss: 0.028755536015626745\n",
      "--------------------------\n",
      "310th iteration\n",
      "Loss: 0.028679037904415637\n",
      "--------------------------\n",
      "320th iteration\n",
      "Loss: 0.028610789354315342\n",
      "--------------------------\n",
      "330th iteration\n",
      "Loss: 0.028549803467149297\n",
      "--------------------------\n",
      "340th iteration\n",
      "Loss: 0.028495223187997555\n",
      "--------------------------\n",
      "350th iteration\n",
      "Loss: 0.02844630350208678\n",
      "--------------------------\n",
      "360th iteration\n",
      "Loss: 0.028402402021287583\n",
      "--------------------------\n",
      "370th iteration\n",
      "Loss: 0.028362954059370372\n",
      "--------------------------\n",
      "380th iteration\n",
      "Loss: 0.02832746694606183\n",
      "--------------------------\n",
      "390th iteration\n",
      "Loss: 0.028295507623768014\n",
      "--------------------------\n",
      "400th iteration\n",
      "Loss: 0.0282666942913605\n",
      "--------------------------\n",
      "410th iteration\n",
      "Loss: 0.028240695844412828\n",
      "--------------------------\n",
      "420th iteration\n",
      "Loss: 0.02821721334805504\n",
      "--------------------------\n",
      "430th iteration\n",
      "Loss: 0.028195984258928428\n",
      "--------------------------\n",
      "440th iteration\n",
      "Loss: 0.02817678064675932\n",
      "--------------------------\n",
      "450th iteration\n",
      "Loss: 0.028159392608472292\n",
      "--------------------------\n",
      "460th iteration\n",
      "Loss: 0.028143638639170805\n",
      "--------------------------\n",
      "470th iteration\n",
      "Loss: 0.02812935436962001\n",
      "--------------------------\n",
      "480th iteration\n",
      "Loss: 0.028116396946648886\n",
      "--------------------------\n",
      "490th iteration\n",
      "Loss: 0.028104633731805682\n",
      "--------------------------\n",
      "500th iteration\n",
      "Loss: 0.028093950765035805\n",
      "--------------------------\n",
      "510th iteration\n",
      "Loss: 0.02808423980888782\n",
      "--------------------------\n",
      "520th iteration\n",
      "Loss: 0.028075411718313313\n",
      "--------------------------\n",
      "530th iteration\n",
      "Loss: 0.028067379431304745\n",
      "--------------------------\n",
      "540th iteration\n",
      "Loss: 0.028060071432634393\n",
      "--------------------------\n",
      "550th iteration\n",
      "Loss: 0.02805341652142746\n",
      "--------------------------\n",
      "560th iteration\n",
      "Loss: 0.02804735347481823\n",
      "--------------------------\n",
      "570th iteration\n",
      "Loss: 0.02804182803767496\n",
      "--------------------------\n",
      "580th iteration\n",
      "Loss: 0.02803679174881163\n",
      "--------------------------\n",
      "590th iteration\n",
      "Loss: 0.02803219912639319\n",
      "--------------------------\n",
      "600th iteration\n",
      "Loss: 0.028028009774620066\n",
      "--------------------------\n",
      "610th iteration\n",
      "Loss: 0.028024185937328396\n",
      "--------------------------\n",
      "620th iteration\n",
      "Loss: 0.028020697180740163\n",
      "--------------------------\n",
      "630th iteration\n",
      "Loss: 0.028017508827696998\n",
      "--------------------------\n",
      "640th iteration\n",
      "Loss: 0.028014599664690894\n",
      "--------------------------\n",
      "650th iteration\n",
      "Loss: 0.028011940239872864\n",
      "--------------------------\n",
      "660th iteration\n",
      "Loss: 0.028009510097464323\n",
      "--------------------------\n",
      "670th iteration\n",
      "Loss: 0.02800728838157872\n",
      "--------------------------\n",
      "680th iteration\n",
      "Loss: 0.02800525901684155\n",
      "--------------------------\n",
      "690th iteration\n",
      "Loss: 0.02800340136282769\n",
      "--------------------------\n",
      "700th iteration\n",
      "Loss: 0.028001703383809994\n",
      "--------------------------\n",
      "710th iteration\n",
      "Loss: 0.02800014852205312\n",
      "--------------------------\n",
      "720th iteration\n",
      "Loss: 0.027998727841645085\n",
      "--------------------------\n",
      "730th iteration\n",
      "Loss: 0.027997426256329158\n",
      "--------------------------\n",
      "740th iteration\n",
      "Loss: 0.027996235772211546\n",
      "--------------------------\n",
      "750th iteration\n",
      "Loss: 0.027995145362942835\n",
      "--------------------------\n",
      "760th iteration\n",
      "Loss: 0.027994146321531355\n",
      "--------------------------\n",
      "770th iteration\n",
      "Loss: 0.027993233250835976\n",
      "--------------------------\n",
      "780th iteration\n",
      "Loss: 0.027992394933517878\n",
      "--------------------------\n",
      "790th iteration\n",
      "Loss: 0.027991628601048646\n",
      "--------------------------\n",
      "800th iteration\n",
      "Loss: 0.027990925891427182\n",
      "--------------------------\n",
      "810th iteration\n",
      "Loss: 0.027990282242666968\n",
      "--------------------------\n",
      "820th iteration\n",
      "Loss: 0.027989691770542124\n",
      "--------------------------\n",
      "830th iteration\n",
      "Loss: 0.027989150523572166\n",
      "--------------------------\n",
      "840th iteration\n",
      "Loss: 0.027988656270085878\n",
      "--------------------------\n",
      "850th iteration\n",
      "Loss: 0.02798820068743216\n",
      "--------------------------\n",
      "860th iteration\n",
      "Loss: 0.027987784068097418\n",
      "--------------------------\n",
      "870th iteration\n",
      "Loss: 0.027987402401757223\n",
      "--------------------------\n",
      "880th iteration\n",
      "Loss: 0.027987052263934595\n",
      "--------------------------\n",
      "890th iteration\n",
      "Loss: 0.02798673184213127\n",
      "--------------------------\n",
      "900th iteration\n",
      "Loss: 0.02798643699585613\n",
      "--------------------------\n",
      "910th iteration\n",
      "Loss: 0.02798616590134384\n",
      "--------------------------\n",
      "920th iteration\n",
      "Loss: 0.02798591817774554\n",
      "--------------------------\n",
      "930th iteration\n",
      "Loss: 0.027985691581790102\n",
      "--------------------------\n",
      "940th iteration\n",
      "Loss: 0.02798548368542523\n",
      "--------------------------\n",
      "950th iteration\n",
      "Loss: 0.02798529173142994\n",
      "--------------------------\n",
      "960th iteration\n",
      "Loss: 0.02798511539152472\n",
      "--------------------------\n",
      "970th iteration\n",
      "Loss: 0.0279849559092189\n",
      "--------------------------\n",
      "980th iteration\n",
      "Loss: 0.027984807403203887\n",
      "--------------------------\n",
      "990th iteration\n",
      "Loss: 0.027984672077706347\n",
      "--------------------------\n",
      "1000th iteration\n",
      "Loss: 0.027984547681046183\n",
      "--------------------------\n",
      "1010th iteration\n",
      "Loss: 0.027984432316086622\n",
      "--------------------------\n",
      "1020th iteration\n",
      "Loss: 0.027984327254092403\n",
      "--------------------------\n",
      "1030th iteration\n",
      "Loss: 0.027984231961234663\n",
      "--------------------------\n",
      "1040th iteration\n",
      "Loss: 0.02798414317303563\n",
      "--------------------------\n",
      "1050th iteration\n",
      "Loss: 0.02798406346988146\n",
      "--------------------------\n",
      "1060th iteration\n",
      "Loss: 0.027983987815748505\n",
      "--------------------------\n",
      "1070th iteration\n",
      "Loss: 0.02798391926207567\n",
      "--------------------------\n",
      "1080th iteration\n",
      "Loss: 0.02798385780802478\n",
      "--------------------------\n",
      "1090th iteration\n",
      "Loss: 0.027983798935823333\n",
      "--------------------------\n",
      "1100th iteration\n",
      "Loss: 0.02798374572120501\n",
      "--------------------------\n",
      "1110th iteration\n",
      "Loss: 0.027983698314065046\n",
      "--------------------------\n",
      "1120th iteration\n",
      "Loss: 0.027983652997949963\n",
      "--------------------------\n",
      "1130th iteration\n",
      "Loss: 0.02798361220983014\n",
      "--------------------------\n",
      "1140th iteration\n",
      "Loss: 0.027983574968535672\n",
      "--------------------------\n",
      "1150th iteration\n",
      "Loss: 0.027983540716421833\n",
      "--------------------------\n",
      "1160th iteration\n",
      "Loss: 0.027983508877925646\n",
      "--------------------------\n",
      "1170th iteration\n",
      "Loss: 0.027983478893793226\n",
      "--------------------------\n",
      "1180th iteration\n",
      "Loss: 0.027983453705098763\n",
      "--------------------------\n",
      "1190th iteration\n",
      "Loss: 0.02798342896357245\n",
      "--------------------------\n",
      "1200th iteration\n",
      "Loss: 0.027983406069225707\n",
      "--------------------------\n",
      "1210th iteration\n",
      "Loss: 0.027983386063191333\n",
      "--------------------------\n",
      "1220th iteration\n",
      "Loss: 0.02798336692170046\n",
      "--------------------------\n",
      "1230th iteration\n",
      "Loss: 0.02798334780965922\n",
      "--------------------------\n",
      "1240th iteration\n",
      "Loss: 0.027983332451927464\n",
      "CPU times: user 337 ms, sys: 45.5 ms, total: 382 ms\n",
      "Wall time: 338 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "    alpha=7,\n",
       "    loss=<dojo.losses.CrossEntropy object at 0x103d31940>,\n",
       "    regularizer=<dojo.regularizers.L2 object at 0x103d319b0>,\n",
       "    verbose=True,\n",
       "    intercept=-13.46808533406562,\n",
       "    coefs=[[8.745498]\n",
       " [8.745498]],\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
